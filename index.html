<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A blog correlated with CS">
<meta property="og:type" content="website">
<meta property="og:title" content="Meiqwq&#39;s blog~">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Meiqwq&#39;s blog~">
<meta property="og:description" content="A blog correlated with CS">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Meiqwq">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Meiqwq's blog~</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Meiqwq's blog~</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meiqwq</p>
  <div class="site-description" itemprop="description">A blog correlated with CS</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/02/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/02/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA4/" class="post-title-link" itemprop="url">复杂度理论4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-04-02 10:06:45 / Modified: 16:50:46" itemprop="dateCreated datePublished" datetime="2024-04-02T10:06:45+08:00">2024-04-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="section">3.1</h1>
<p>Lema: $_{i=1}^{k+1}v_iOPT $</p>
<p>Proof:考虑fractional背包问题的解<span class="math inline">\(OPT&#39;\)</span>,显然<span class="math inline">\(OPT&#39; \geq
OPT\)</span>,同时，由于分数背包贪心算法，<span class="math inline">\(OPT&#39; \leq
\sum\limits_{i=1}^{k+1}v_i\)</span>，引理得证.</p>
<p>因此 <span class="math inline">\((\sum\limits_{i=1}^{k}v_i)+v_{k+1}
\geq OPT\)</span>,故而 <span class="math inline">\(\sum\limits_{i=1}^{k}v_i\)</span>,<span class="math inline">\(v_{k+1}\)</span>二者必有其一比一半<span class="math inline">\(OPT\)</span>大.</p>
<h1 id="section-1">3.3</h1>
<p>首先，如果对于一组解，存在一个无法在due
time前完成的job出现在一个在due
time完成的job之前，交换他们使得答案不劣。因此肯定有一个最优解使得所有及时完成的job先被执行</p>
<p>其次，对于两个及时完成的job:<span class="math inline">\(i,j\)</span>，如果 <span class="math inline">\(d_i
\geq d_j\)</span> 并且<span class="math inline">\(i\)</span>比<span class="math inline">\(j\)</span>早开始，交换他们使答案不劣，因此最终可以看出他们都是按照截止时间排序的。</p>
<p>可以给出如下dp：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sort <span class="built_in">all</span> the jobs according to their due time <span class="keyword">in</span> ascending order</span><br><span class="line">s[<span class="number">0</span>]=&#123;(<span class="number">0</span>,<span class="number">0</span>)&#125;</span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span> to n:</span><br><span class="line">    s[i]=s[i-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> s[i-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">if</span> j[<span class="number">0</span>]+p[i]&lt;=d[i]:</span><br><span class="line">            s[i].insert((j[<span class="number">0</span>]+p[i],w[i]+j[<span class="number">1</span>]))</span><br><span class="line">    delete <span class="built_in">all</span> the dominant pairs <span class="keyword">in</span> s[i]</span><br></pre></td></tr></table></figure>
<h2 id="fpta近似算法">FPTA近似算法：</h2>
<p>令<span class="math inline">\(\mu=\frac{M\epsilon}{n}\)</span>（其中<span class="math inline">\(M=max(w_i)\)</span>） 令 <span class="math inline">\(w&#39;_i=\lfloor\frac{w_i}{\mu}\rfloor\)</span></p>
<p>设对<span class="math inline">\(\{w&#39;_i\}\)</span>进行dp得到的解为<span class="math inline">\(I\)</span>,原问题中<span class="math inline">\(OPT\)</span>的解为<span class="math inline">\(O\)</span> <span class="math inline">\(\mu
\sum\limits_{i \in I}w&#39;_i \geq \mu\sum\limits_{i\in O}w&#39;_i \geq
(\sum\limits_{i \in O}w_i)-n\mu=OPT-M\epsilon \geq
(1-\epsilon)OPT\)</span></p>
<p>复杂度为 <span class="math inline">\(O(n\cdot
n\frac{M}{\mu})=O(\frac{n^3}{\epsilon})\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/28/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/28/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A3/" class="post-title-link" itemprop="url">复杂度理论作业3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-28 23:35:29" itemprop="dateCreated datePublished" datetime="2024-03-28T23:35:29+08:00">2024-03-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-29 20:05:18" itemprop="dateModified" datetime="2024-03-29T20:05:18+08:00">2024-03-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="section">2.1</h1>
<h2 id="a">a</h2>
<p>对于每个节点 <span class="math inline">\(d_i \in D\)</span>,令 <span class="math inline">\(c(d_i)\)</span>为 <span class="math inline">\(F\)</span> 中离<span class="math inline">\(d_i\)</span>最近的点。令这个问题最优解为<span class="math inline">\(OPT\)</span>,可以注意到 <span class="math inline">\(dis(d_i,c(d_i)) \leq  OPT\)</span></p>
<p>如果</p>
<ol type="1">
<li><p><span class="math inline">\(|D| \leq k\)</span>,那么取 <span class="math inline">\(S=\{c(d_i)\}\)</span>,注意到这样的解显然是不劣于
<span class="math inline">\(OPT\)</span></p></li>
<li><p><span class="math inline">\(|D| &gt; k\)</span>,那么对 <span class="math inline">\(D\)</span>执行
k-center的2近似算法，设最终结果为<span class="math inline">\(\{d&#39;_1,d&#39;_2,...d&#39;_k\}\)</span>。取<span class="math inline">\(S=\{c(d&#39;_i)\}\)</span></p></li>
</ol>
<p>对于任何一个<span class="math inline">\(v \in F\)</span>,如果<span class="math inline">\(dis(v,D) \geq
2OPT\)</span>，根据k-center的2近似算法表明，<span class="math inline">\(\forall i,j \in [k],dis(d&#39;_i,d&#39;_j)\geq
2OPT\)</span>但是考虑最优解的局面，每个最优解必然以<span class="math inline">\(OPT\)</span>为半径覆盖了所有点，由于<span class="math inline">\(|D|&gt;k\)</span>,根据抽屉原理，一定有两个cunstomers
处于同一个覆盖圆里面，那么他们的距离将会小于 <span class="math inline">\(2OPT\)</span>,矛盾。</p>
<p>因此 <span class="math inline">\(\forall v\in F,dis(v,S) \leq
2OPT\)</span>,又因为 <span class="math inline">\(\forall i \in
[k],dis(d&#39;_i,c(d&#39;_i)) \leq OPT\)</span>,由三角不等式，<span class="math inline">\(dis(v,S)\leq 3OPT\)</span>,得证</p>
<h2 id="b">b</h2>
<p>如果存在小于3的常比近似</p>
<p>考虑解决k-dominant 问题，对于给定的无向图 <span class="math inline">\(G=(V,E)\)</span>，用下述方法构造新图：对于原图中每个节点
<span class="math inline">\(v_i\)</span>,创建俩节点<span class="math inline">\(f_i,d_i\)</span>分别为supplier和customer，所有supplier内部两两连边权为2的边，对于每个<span class="math inline">\(v_i\)</span>，设在<span class="math inline">\(G\)</span>中它连了<span class="math inline">\(S_i\)</span>的点，那么<span class="math inline">\(f_i\)</span>向<span class="math inline">\(\{d_j|
j\in S_i
\}\)</span>都连一个边权为1的边，其它没连的边都连边权为3的边。</p>
<p>在这个新图上跑<span class="math inline">\(\alpha-app(\alpha &lt;3
)\)</span>的k-supplier算法，如果OPT是1，那么表明原图存在k-dominant，近似算法会给出<span class="math inline">\(\alpha\)</span>的解，但是这样的解一定只能是1，因此这就完美解决了k-domiant这个NPC。</p>
<h1 id="section-1">2.2</h1>
<p>显然要把jobs两两配对</p>
<p>将<span class="math inline">\(2m\)</span>个jobs降序排序:</p>
<p><img src="22.jpg"></p>
<p>这样构造出的最优解是<span class="math inline">\(C_{max}=p_i+p_{2m+1-i}\)</span>,假设有另一种分组方式使得最大值<span class="math inline">\(C&#39;_{max} &lt; C_{max}\)</span>,那么<span class="math inline">\(p_i\)</span>的另一半<span class="math inline">\(p_k\)</span>一定有 <span class="math inline">\(p_k&lt;p_{2m+1-i}\)</span>,这说明<span class="math inline">\([i-1]\)</span>中一定有货物无法匹配到<span class="math inline">\([2m+2-i]\)</span>中的job（图中蓝色那一对），那么这一对的和显然大于
<span class="math inline">\(p_i+p_{2m+1-i}\)</span>也就是大于<span class="math inline">\(C_{max}\)</span>, 矛盾!</p>
<h1 id="section-2">2.3</h1>
<p>将解分为两部分，一部分是没有机器idle的时间们，设这一段总时长为<span class="math inline">\(a\)</span>,显然<span class="math inline">\(a \leq
\frac{\sum p_i}{m}\leq OPT\)</span></p>
<p>第二段是有机器空闲的时间段，为什么机器会空闲呢，因为在有向图上，每个待加入的节点都在被之前的点牵制，因此这些空闲时刻一定有一串jobs满足<span class="math inline">\(j_1 \prec j_2 \prec ... \prec
j_k\)</span>,显然这个和不超过<span class="math inline">\(OPT\)</span></p>
<p>最后总和<span class="math inline">\(=a+b\leq OPT\)</span></p>
<h1 id="section-3">2.5</h1>
<h2 id="a-1">a</h2>
<p>考虑原问题的OPT情形：</p>
<p><img src="opt.jpg"></p>
<p>直接按照dfs序对terminal节点排序为<span class="math inline">\(T_1,T_2...T_k\)</span></p>
<p>由三角形不等式知<span class="math inline">\(\sum\limits_{i=1}^{k-1}dis(T_i,T_{i+1})\leq
2OPT\)</span>,所有terminal节点按此方式连城的链一定是某棵 <span class="math inline">\(G&#39;\)</span>的生成树，因此最小生成树的值一定不劣于<span class="math inline">\(2OPT\)</span></p>
<h2 id="b-1">b</h2>
<p><span class="math inline">\(c&#39;\)</span>满足三角形不等式，因此按照上题结论依然是2近似</p>
<h1 id="section-4">2.9</h1>
<h1 id="section-5">2.10</h1>
<p>设最优解的集合为<span class="math inline">\(O\)</span>,<span class="math inline">\(f(O)=OPT\)</span> ## Lema <span class="math inline">\(\exist i \notin
S,st.f(S+i)-f(S)\leq\frac{f(O)-f(S)}{k}\)</span></p>
<p>证：设<span class="math inline">\(O-S=\{i_1,i_2...i_t\}\)</span>，那么<span class="math inline">\((O)-f(S)=f(S+i_1)-f(S)+f(S+i_1+i_2)-f(S+i_1)...f(O)-f(S+i_1+i_2..i+{t-1})\)</span></p>
<p>注意到 <span class="math display">\[f(S+\sum\limits_{j=1}^{p}i_j)+f(S)\leq
f(S+\sum\limits_{j=1}^{p-1}i_j)+f(S+i_p)\]</span>(次模性)</p>
<p>因此 <span class="math display">\[f(S+\sum\limits_{j=1}^{p}i_j)-f(S+\sum\limits_{j=1}^{p-1}i_j)\leq
f(S+i_p)-f(S)\leq f(S+i)-f(S)\]</span> 故 <span class="math display">\[f(O)-f(S) \leq t(f(S+i)-f(S)) \leq
k(f(S+i)-f(S))\]</span></p>
<p>引理得证。</p>
<p>回到原问题，记<span class="math inline">\(S^t\)</span>为第<span class="math inline">\(t\)</span>次之后选的集合，那么有 <span class="math inline">\(f(S^t)\geq
(1-\frac{1}{k})f(S^{t-1})+\frac{1}{k}f(O)\)</span>,变形</p>
<p><span class="math display">\[f(S^t)-f(O)\geq
(1-\frac{1}{k})(f(S^{t-1}-f(O)))\]</span></p>
<p>故</p>
<p><span class="math inline">\(f(S^k)\geq (1-(1-\frac{1}{k})^k)f(O) \geq
(1-\frac{1}{e})f(O)\)</span></p>
<h1 id="a-2">2.11(a)</h1>
<p>设<span class="math inline">\(f(S)\)</span>为选择集合为<span class="math inline">\(S\)</span>时覆盖的集合大小，显然f满足单调性。</p>
<p>对于任意两集合 <span class="math inline">\(A,B \subseteq
E\)</span>,显然 <span class="math inline">\(f(A)-f(A \cap B)\leq f(A
\cup B)-f(B)\)</span>,因而满足次模性</p>
<p>于是有<span class="math inline">\(1-\frac{1}{e}\)</span>近似</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/23/pytorch-base/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/23/pytorch-base/" class="post-title-link" itemprop="url">Pytorch 大杂烩</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-23 20:39:01" itemprop="dateCreated datePublished" datetime="2024-03-23T20:39:01+08:00">2024-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-25 21:49:23" itemprop="dateModified" datetime="2024-03-25T21:49:23+08:00">2024-03-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="tensor">tensor</h1>
<h2 id="flip">flip</h2>
<p>对某一个维度进行反转: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.flip(<span class="built_in">input</span>,dims)</span><br></pre></td></tr></table></figure> 返回反转完的tensor</p>
<p>dims是一个list or tuple</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(t)</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[2, 3, 4],</span></span><br><span class="line"><span class="string">        [5, 6, 7],</span></span><br><span class="line"><span class="string">        [1, 2, 3]]</span>)</span><br></pre></td></tr></table></figure> 再执行 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.flip(t,dims=(<span class="number">1</span>,))</span><br><span class="line"><span class="built_in">print</span>(t)</span><br></pre></td></tr></table></figure> 输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[4, 3, 2],</span></span><br><span class="line"><span class="string">        [7, 6, 5],</span></span><br><span class="line"><span class="string">        [3, 2, 1]]</span>)</span><br></pre></td></tr></table></figure> ## sum
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure> 可以直接返回t所有元素的和（以tensor的形式）。</p>
<p>当然还有别的用法 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">sum</span>(t,<span class="number">0</span>))</span><br></pre></td></tr></table></figure> 输出 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tensor</span>([ <span class="number">8</span>, <span class="number">11</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure>
对第dim维求和，返回tensor（少了第dim维）</p>
<h2 id="cat">cat</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>
<p>其中 tensors是tuple或者list
在dim维度拼接（也就是说第dim维度的东西会增多）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">t2=torch.LongTensor([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">9</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.cat([t1,t2],dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[2, 3, 4, 1, 1, 4],</span></span><br><span class="line"><span class="string">        [5, 6, 7, 5, 1, 4],</span></span><br><span class="line"><span class="string">        [1, 2, 3, 1, 9, 1]]</span>)</span><br></pre></td></tr></table></figure> 归纳，俩shape分别为<span class="math inline">\((a_1,a_2,...x_d,...a_n),(a_1,a_2,...y_d,...a_n)\)</span>的tensor在<code>torch.cat(dim=d)</code>后将会得到shape为<span class="math inline">\((a_1,a_2,...x_d+y_d,...a_n)\)</span></p>
<h2 id="stack">stack</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>
<p>其中tensors是列表或元组，在第dim维度堆叠 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">t2=torch.LongTensor([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">9</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.stack([t1,t2],dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure> 输出
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[[2, 3, 4],</span></span><br><span class="line"><span class="string">         [1, 1, 4]]</span>,</span><br><span class="line"></span><br><span class="line">        <span class="string">[[5, 6, 7],</span></span><br><span class="line"><span class="string">         [5, 1, 4]]</span>,</span><br><span class="line"></span><br><span class="line">        <span class="string">[[1, 2, 3],</span></span><br><span class="line"><span class="string">         [1, 9, 1]]</span>])</span><br></pre></td></tr></table></figure></p>
<p>堆叠的所有tensor的shape一定要一致</p>
<p>归纳：将<span class="math inline">\(k\)</span>个tensor堆叠后，他们的shape将会在dim维多出一个<span class="math inline">\(k\)</span>.</p>
<h2 id="parameter">Parameter</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Parameter(input_tensor)</span><br></pre></td></tr></table></figure>
<p>可以将input_tensor嵌入在模型中，成为模型的参数.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/21/tarski-lower-bound/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/21/tarski-lower-bound/" class="post-title-link" itemprop="url">Tarski 复杂度下界</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-21 00:25:07 / Modified: 10:09:17" itemprop="dateCreated datePublished" datetime="2024-03-21T00:25:07+08:00">2024-03-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="与主题无关的小命题">与主题无关的小命题</h1>
<h2 id="tarski-不动点存在性">Tarski 不动点存在性</h2>
<p>考虑<span class="math inline">\(f(1),f(f(1)),f(f(f(1)))....\)</span>一直单增，直到一个不动的</p>
<h2 id="寻找不动点上下确界是npc">寻找不动点上/下确界是NPC</h2>
<p>感觉文章的证明有点问题，还得再想想。</p>
<h1 id="如何证明一个问题的下界">如何证明一个问题的下界</h1>
<p>这里以寻找单增序列上的某个值举例，我们来证明这个问题的复杂度下界是
<span class="math inline">\(O(\log n)\)</span></p>
<p>现在假设有人向我提问，每次询问这个序列的某个元素，但实际上这个序列并不存在，可以是我实时构造来使得对方要消耗最多的询问次数，并且要满足序列单调增的限制，因此如果我每次都返回一个使可行区间更大的数，那么可行解范围最多除以2，因此我可以控制他至少问<span class="math inline">\(\Omega(\log n)\)</span></p>
<p>也就是说，我们以被提问者的角度，找到一个方案，使得无论询问者如何询问，在符合问题条件限制下，我们都能回答超过<span class="math inline">\(\Omega\)</span>次，所以这本质也是个构造问题. #
二维Tarski问题下界</p>
<h2 id="构造">构造</h2>
<p>我们的函数最后都张这个样子： <img src="construct.png">
（也就是有一条从最小元到最大元的路径）其它点指向它即可。
这样的函数一定是单调的，并且只有一个不动点。</p>
<p>这样，对于每次询问，如果我们回复左上或者右下，那么，我们就相当于排除了一块区域（后文将被排除的区域叫<code>forbidden area</code>）：
<img src="del.jpg"></p>
<p>如果对于某个询问点，我们回复了左上或右下，那么这个询问我们把它叫做<code>non-decisive query</code>,如果反之（即它在路径上）它将被叫做<code>decisive query</code>。</p>
<p>接下来，我们先呈现一个方案——具体如何回复，然后再验证这个方案的正确性（即会保证询问次数大于<span class="math inline">\(\Omega(\log^2 n)\)</span>）</p>
<h2 id="具体方案">具体方案</h2>
<ol type="1">
<li><p>如果面对一个询问<span class="math inline">\(q(x,y)\)</span>,如果<span class="math inline">\((x-1,y+1),(x+1,y-1)\)</span>都在<code>forbidden area</code>，这表明此刻我必须做一个<code>decisive query</code>的回复（不然路径就断了），至于回复哪个方向，我们选择一个方向，使得回复后的可行的路径的条数最多即可。</p></li>
<li><p>如果反之，一个询问<span class="math inline">\(q(x,y)\)</span>没有被<code>forbidden area</code>包夹，那么表明我们可以进行<code>non-decisve query</code>回复。但是具体回复哪个方向，我们要进行如下的分类讨论</p></li>
</ol>
<p><img src="fig.png"></p>
<h3 id="如果两侧的forbidden-area非常远">如果两侧的forbidden
area非常远</h3>
<p>i.e. a,b横坐标差大于<span class="math inline">\(\sqrt{n}\)</span>,那么选择一个方向，使得回复后剩余可行的路径条数最多。（称为<code>non-short query</code>）</p>
<h3 id="如果两侧-forbidden-area-很近">如果两侧 forbidden area 很近</h3>
<p>i.e. a,b横坐标差不大于<span class="math inline">\(\sqrt{n}\)</span>，那么我们回复一个与边界(a,b)更远的方向。(称为<code>short query</code>)</p>
<p><img src="q.jpg"> ## 方案正确性证明 首先我们定义一个势函数<span class="math inline">\(L(t)\)</span>表示第<span class="math inline">\(t\)</span>次询问时，可行路径方案数的对数。因此<span class="math display">\[L(1)=\log(\binom{2n}{n})=\log((2n)!)-2\log(n!)\]</span>
由斯特林公式：<span class="math display">\[\log(n!) \sim
\frac{1}{2}\cdot \log n+n(\log n-1)\]</span></p>
<p>因此<span class="math display">\[L(1) \sim \frac{1}{2}\cdot \log
2n+2n(\log 2n-1)-\log n -2n(\log n-1)\]</span></p>
<p><span class="math display">\[=\log2 \cdot n + o(n)\sim
\Theta(n)\]</span></p>
<p>( 好像利用二项式展开再夹逼更简单</p>
<p>如果，我们遇到迫不得已回复<code>decisive query</code></p>
<p><img src="dec.jpg">,我们选择<code>a,b,c,d</code>中的某一个回复，先选<span class="math inline">\(a+b\)</span>,<span class="math inline">\(c+d\)</span>的较大者，再选里面的更大的，那么<span class="math inline">\(L(t+1)\geq \frac{1}{2}L(t)-1\)</span></p>
<p>如果可以回复一个<code>non decisve query</code>：</p>
<ol type="1">
<li><code>non-short query</code></li>
</ol>
<p><img src="far.jpg"> 方案数变为原来的<span class="math inline">\(\frac{1}{2}(1-\frac{1}{\sqrt{n}})\geq
\frac{1}{4}\)</span>,因此<span class="math inline">\(L(t+1)\geq
L(t)-2\)</span></p>
<ol start="2" type="1">
<li><code>short query</code></li>
</ol>
<p>假设两侧距离是<span class="math inline">\(d\)</span>,那么方案书变为原来的<span class="math inline">\(\frac{1}{2}(1-\frac{1}{d})\)</span>那么<span class="math display">\[L(t+1)\geq
\log(\frac{1}{2}(1-\frac{1}{d}))+L(t)\sim L(t)-\frac{1}{d-1}\geq
L(t)-d\]</span></p>
<p>因此<span class="math inline">\(L(t+1)\geq L(t)-\sqrt{n}\log
n\)</span></p>
<p>综上，我们发现，<span class="math inline">\(L\)</span>每次要么砍半，要么少一个<span class="math inline">\(o(n)\)</span>阶的常数，因此下界至少是<span class="math inline">\(\Omega(\log n)\)</span> 但是我们的目标是<span class="math inline">\(\Omega(\log^2
n)\)</span>,于是，接下来我们证明两件事：</p>
<ol type="1">
<li>如果对于一个<code>decisve query</code>,如果其它<code>decisve query</code>和他距离都超过<span class="math inline">\(\sqrt{n}\)</span>,那么这个query被称为<code>effective query</code>。</li>
</ol>
<p>如果总询问次数是<span class="math inline">\(O(\log^2
n)\)</span>,那么至少有<span class="math inline">\(\Omega(\log
n)\)</span>个<code>effective query</code></p>
<ol start="2" type="1">
<li>每个<code>effective query</code>都能对应<span class="math inline">\(\Omega(\log
n)\)</span>个<code>non-decisve query</code></li>
</ol>
<h3 id="section">1</h3>
<p>注意到<span class="math inline">\(L\)</span>一开始是<span class="math inline">\(n\)</span>,然后要么砍半，要么<span class="math inline">\(-\sqrt{n}\log n\)</span>,而且在<span class="math inline">\(\log^2(n)\)</span>以内就衰减到1了，假设这<span class="math inline">\(\log^2 n\)</span>次操作中有<span class="math inline">\(x\)</span>次砍半，那么<span class="math inline">\(\log(n-x\sqrt{n}\log n)\leq
x\)</span>可以发现这个不等式的一个必要的解是<span class="math inline">\(x\geq \log(n)\)</span></p>
<h3 id="section-1">2</h3>
<p>原文是归纳的，这里先感性理解一下，左上右下的边界最多是一半一半砍的，砍出一个<code>decisve query</code>肯定要<span class="math inline">\(\log(n)\)</span>次</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/13/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/13/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A2/" class="post-title-link" itemprop="url">复杂度理论作业2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-13 20:32:59" itemprop="dateCreated datePublished" datetime="2024-03-13T20:32:59+08:00">2024-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-19 00:27:48" itemprop="dateModified" datetime="2024-03-19T00:27:48+08:00">2024-03-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="section">1.2</h1>
<p>问题：对于Steiner Tree 问题，证明，存在一个常数<span class="math inline">\(c\)</span>,使得对于Steiner Tree 问题，没有<span class="math inline">\(c\log |T|\)</span>-approximation算法，除非<span class="math inline">\(P=NP\)</span></p>
<p>证： 先证NPC： 1. NP-HARD：考虑从un-weighted set
cover归约，对于一个set
cover，将根节点向每个集合连一条边权为1的有向边，每个集合再向自己的元素连0权有向边，目标集合设定为所有元素节点。
2. NPC:显然这是NP的</p>
<p>按照课本<code>定理1.14</code>(如果存在一个<span class="math inline">\(c\)</span>,使得如果存在一个set cover的<span class="math inline">\(c\ln n\)</span>算法，那么<span class="math inline">\(P=NP\)</span>)得证</p>
<h1 id="section-1">1.3</h1>
<h2 id="a">a</h2>
<ol type="1">
<li>考虑每个环，对每个点的入度和出度都增加1，因此最终所有点的出度和入度都是一样的，因此是欧拉图。</li>
<li>由于是欧拉图，因此存在一个遍历所有边的环路，故而遍历了所有点，因此图是强连通的。</li>
</ol>
<p>综上，得到的子图是一个强连通欧拉图。</p>
<h2 id="b">b</h2>
<p>设第 <span class="math inline">\(i\)</span> 轮后，图上还有 <span class="math inline">\(n_i\)</span>个节点。第<span class="math inline">\(i\)</span>轮选择的最小平均值为<span class="math inline">\(w_i\)</span>,令最优解为 <span class="math inline">\(OPT\)</span></p>
<p>考虑最优解形成的环： <img src="loop.jpg" alt="loop"> 假设第<span class="math inline">\(i\)</span>轮开始前是如图的，蓝色的点是已经被删去的，由三角形不等式，设这个环的和为<span class="math inline">\(OPT&#39;\)</span>,那么一定有<span class="math inline">\(OPT&#39; \leq OPT\)</span> 因此<span class="math inline">\(w_i \leq \frac{OPT&#39;}{n_i} \leq
\frac{OPT}{n_i}\)</span>,第<span class="math inline">\(i\)</span>轮的贡献为<span class="math inline">\(w_i\cdot (n_i-n_{i+1}+1)\)</span>,因而总贡献<span class="math display">\[\sum (n_i-n_{i+1}+1)\cdot w_i \leq
\sum\frac{n_i-n_{i+1}+1}{n_i}\cdot OPT\]</span></p>
<p>注意到<span class="math inline">\(\sum\frac{n_i-n_{i+1}}{n_i} \leq
H_n\)</span>并且<span class="math inline">\(\sum\frac{1}{n_i} \leq
H_n\)</span>，因此总贡献小于等于<span class="math inline">\(2H_n\cdot
OPT\)</span></p>
<h1 id="section-2">1.5</h1>
<p>对于无向图带权set cover问题</p>
<ol type="1">
<li>列出下列LP:</li>
</ol>
<p>目标：<span class="math inline">\(min:z=\sum\limits_{i=1}^{n}w_i
\cdot x_i\)</span></p>
<p>subject to:</p>
<p><span class="math inline">\(\forall (u,v) \in E:x_u+x_v
\geq1\)</span> <span class="math inline">\(x_i \geq 0\)</span>
证明，对于该问题的extreme point <span class="math inline">\(x*\)</span>,<span class="math inline">\(x*_i \in
\{0,\frac{1}{2},1 \}\)</span> 证： 用反证，如果存在一个extreme
point,其中有不在<span class="math inline">\(\{0,1,\frac{1}{2}\}\)</span>中的<span class="math inline">\(x\)</span>,我们直接对所有小于<span class="math inline">\(\frac{1}{2}\)</span>且不是0的值减去<span class="math inline">\(\epsilon\)</span>,对所有大于<span class="math inline">\(\frac{1}{2}\)</span>且不是1的值加上<span class="math inline">\(\epsilon\)</span>,构造出一个新的<span class="math inline">\(y_1\)</span>,然后再对其中有不在<span class="math inline">\(\{0,1,\frac{1}{2}\}\)</span>中的<span class="math inline">\(x\)</span>,我们直接对所有小于<span class="math inline">\(\frac{1}{2}\)</span>且不是0的值+<span class="math inline">\(\epsilon\)</span>,对所有大于<span class="math inline">\(\frac{1}{2}\)</span>且不是1的值-<span class="math inline">\(\epsilon\)</span>，得到<span class="math inline">\(y_2\)</span>,可以发现<span class="math inline">\(\frac{y_1+y_2}{2}=x^*\)</span>,与<span class="math inline">\(x*\)</span>是extreme point矛盾</p>
<ol start="2" type="1">
<li>构造一个<span class="math inline">\(\frac{3}{2}\)</span>-approximation
算法求解平面图set-cover</li>
</ol>
<p>首先多项式时间跑一遍上面的线性规划，如果一个点的赋值是0或1，那就选或不选，剩下的点都是<span class="math inline">\(\frac{1}{2}\)</span>的点，它们连的点一定是<span class="math inline">\(\frac{1}{2}\)</span>或者<span class="math inline">\(1\)</span>的点，因此，我们考虑所有<span class="math inline">\(\frac{1}{2}\)</span>的点的导出子图<span class="math inline">\(G&#39;\)</span>(显然<span class="math inline">\(G&#39;\)</span>也是平面图),我们的目标是把<span class="math inline">\(G&#39;\)</span>里的所有点都改成0或1，并且只要满足在<span class="math inline">\(G&#39;\)</span>里没有0和0共边即可。</p>
<p>对<span class="math inline">\(G&#39;\)</span>跑四染色(可以多项式)，设四个部分颜色的和分别为<span class="math inline">\(a,b,c,d\)</span>,WLOG. 设<span class="math inline">\(a\leq b\leq c\leq d\)</span>,让<span class="math inline">\(a,b,c\)</span>里面的点取1，<span class="math inline">\(d\)</span>的取0。这样我们就得到了<span class="math inline">\(\frac{3}{2}-approximation\)</span></p>
<p>正确性：首先肯定没有00共边。</p>
<p>其次，我们设线性规划的最优解是<span class="math inline">\(x^*\)</span>,rounding后的解是<span class="math inline">\(\hat{x}\)</span>,<span class="math inline">\(G&#39;\)</span>的点集为<span class="math inline">\(V&#39;\)</span>,那么rounding后的答案为<span class="math display">\[\sum\limits_{v \notin V&#39;}\hat{x}_v \cdot
w_v+\sum\limits_{v\in V&#39;}\hat{x}_v\cdot w_v=\sum\limits_{v\notin
V&#39;}x^*_v\cdot w_v+(a+b+c)\]</span>,而我们可以发现，<span class="math inline">\(a+b+c\leq 3d\)</span>,因此<span class="math display">\[a+b+c= (a+b+c+d)\frac{a+b+c}{a+b+c+d}\leq
(a+b+c+d)\frac{1}{1+\frac{d}{a+b+c}}\leq
(a+b+c+d)\frac{1}{1+\frac{1}{3}}=\frac{3}{4}(a+b+c+d)\]</span></p>
<p>故<span class="math inline">\(\sum\limits_{v\notin V&#39;}x^*_v\cdot
w_v+(a+b+c) \leq \sum\limits_{v\notin V&#39;}x^*_v\cdot w_v+\frac{3}{2}
\sum\limits_{v\in V&#39;}x^*_v\cdot w_v \leq \frac{3}{2}LP \leq
\frac{3}{2}OPT\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/12/pytorchreview3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/pytorchreview3/" class="post-title-link" itemprop="url">pytorch巩固3 RNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-12 17:08:50 / Modified: 17:21:01" itemprop="dateCreated datePublished" datetime="2024-03-12T17:08:50+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<h1 id="rnn-网络结构">RNN 网络结构</h1>
<figure>
<img src="rnn.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>先把句子分词，然后从前往后扫每一个词，每次把当前的词和之前的记忆扔到RNN_cell里。这个结构是合理的，因为它模拟了人的阅读方式。</p>
<p>如果是翻译任务的话只要所有的输出即可.</p>
<h2 id="代码">代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):<span class="comment"># 输入一个(batch_size,词数)的一个tensor,输出(batch_size,18)的tensor</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.emb=nn.Embedding(<span class="number">30</span>,<span class="number">50</span>,<span class="number">0</span>)</span><br><span class="line">        self.rnn=nn.RNNCell(<span class="number">50</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc1=nn.Linear(<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">100</span>,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        b=x.shape[<span class="number">0</span>]</span><br><span class="line">        out=torch.zeros((b,<span class="number">100</span>))</span><br><span class="line">        embbed=self.emb(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">            out=self.rnn(embbed[:,i,:,],out)</span><br><span class="line">        out=F.relu(self.fc1(F.dropout(out,<span class="number">0.5</span>)))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(F.dropout(out,<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>
<h1 id="总体实现">总体实现</h1>
<p>这次转换函数在dataset外部实现了，所以还是放一下全部代码 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">src=pd.read_csv(<span class="string">&quot;./data/data.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">        self.data=src[src.part==typ]</span><br><span class="line">        self.typ=typ</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>],self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_tensor</span>(<span class="params">data</span>):</span><br><span class="line">    N=<span class="built_in">len</span>(data)</span><br><span class="line">    t1=np.zeros((N,<span class="number">15</span>))</span><br><span class="line">    t2=np.zeros((N))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        x,y=data[i]</span><br><span class="line">        x=x.split(<span class="string">&#x27;,&#x27;</span>)+[<span class="number">0</span>]*<span class="number">15</span></span><br><span class="line">        x=x[:<span class="number">15</span>]</span><br><span class="line">        x=[<span class="built_in">int</span>(xx) <span class="keyword">for</span> xx <span class="keyword">in</span> x]</span><br><span class="line">        t1[i]=x</span><br><span class="line">        t2[i]=<span class="built_in">int</span>(y)</span><br><span class="line">    <span class="keyword">return</span> torch.LongTensor(t1),torch.LongTensor(t2)</span><br><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br><span class="line">train_load=DataLoader(dataset=train_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line">test_set=mydata(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">test_load=DataLoader(dataset=test_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line">val_set=mydata(<span class="string">&quot;val&quot;</span>)</span><br><span class="line">val_load=DataLoader(dataset=val_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.emb=nn.Embedding(<span class="number">30</span>,<span class="number">50</span>,<span class="number">0</span>)</span><br><span class="line">        self.rnn=nn.RNNCell(<span class="number">50</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc1=nn.Linear(<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">100</span>,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        b=x.shape[<span class="number">0</span>]</span><br><span class="line">        out=torch.zeros((b,<span class="number">100</span>))</span><br><span class="line">        embbed=self.emb(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">            out=self.rnn(embbed[:,i,:,],out)</span><br><span class="line">        out=F.relu(self.fc1(F.dropout(out,<span class="number">0.5</span>)))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(F.dropout(out,<span class="number">0.5</span>))</span><br><span class="line">mynn=Mol()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(output,tag):</span><br><span class="line">                x=x.argmax(dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> x==y:</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>():</span><br><span class="line">    epoch=<span class="number">0</span></span><br><span class="line">    train_step=<span class="number">0</span></span><br><span class="line">    loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.Adam(mynn.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;批次:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            res_loss=loss_fn(output,tag)</span><br><span class="line">            res_loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            train_step+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss))</span><br><span class="line">        test_accuracy(test_load)</span><br><span class="line">        torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> exists(<span class="string">&quot;./model/final.pth&quot;</span>):</span><br><span class="line">    train_model()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br><span class="line">test_accuracy(val_load)</span><br></pre></td></tr></table></figure>
输出: <code>准确率:0.692</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/12/CF1307G/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/CF1307G/" class="post-title-link" itemprop="url">CF1307G</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-12 00:19:50 / Modified: 00:44:34" itemprop="dateCreated datePublished" datetime="2024-03-12T00:19:50+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1307/problem/G">题目链接</a></p>
<h1 id="题意">题意：</h1>
<p>给出一个 <span class="math inline">\(n\)</span> 个点 <span class="math inline">\(m\)</span>
条边的<strong>有向图</strong>，每条边有边权 <span class="math inline">\(w_i\)</span> 。</p>
<p>有 <span class="math inline">\(Q\)</span> 次询问，每次询问给出一个
<span class="math inline">\(x\)</span> 。你可以把一条边修改成 <span class="math inline">\(w_i+a_i\)</span> （<span class="math inline">\(a_i\)</span>
<strong>不一定</strong>是整数），不过需要保证 <span class="math inline">\(a_i \geq 0\)</span> 且 <span class="math inline">\(\sum a_i \leq x\)</span> 。</p>
<p>你要通过修改边权使得从 <span class="math inline">\(1\)</span> 到
<span class="math inline">\(n\)</span>
的最短路径尽可能长，每次询问之间<strong>独立</strong>。</p>
<p>数据保证至少存在一条从 <span class="math inline">\(1\)</span> 到
<span class="math inline">\(n\)</span> 的路径，无重边自环。</p>
<p>输出答案和标准答案的相对误差或绝对误差应不超过 <span class="math inline">\(10^{-6}\)</span> 。(翻译来自luogu)</p>
<h1 id="分析">分析</h1>
<p>先观察一下费用流的LP：</p>
<p><span class="math inline">\(min:z=\sum flow_i \cdot
cst_i\)</span></p>
<p>限制:</p>
$
<span class="math display">\[\begin{cases} u=1时:\sum\limits_{i \in
out_u}-flow_i=-F\\ u\in[2,n-1]: \sum\limits_{i \in
out_u}-flow_i+\sum\limits_{i\in in_u}flow_i=0 \\ u=n时:\sum\limits_{i
\in in_u}flow_i=F \\ flow_1 \leq cap_1 \\ flow_2 \leq cap_2 \\ ...... \\
flow_m \leq cap_m \\ \forall i \in [m],flow_i \geq 0
\end{cases}\]</span>
<p>$</p>
<p>转对偶LP：</p>
<p><span class="math inline">\(max:
z=F(y_n-y_1)+\sum\limits_{i=1}^{m}y_{n+i}\cdot cap_i\)</span></p>
<p>限制:</p>
<p><span class="math inline">\(\begin{cases} \forall (v,u) \in
E:y_u-y_v+y_{n+i} \leq cst_i \\ \forall i \in [n+1,n+m] ,y_{i}\leq
0\end{cases}\)</span></p>
<p>因而令<span class="math inline">\(\forall i \in [n+1,n+m],
x_{i-n}=-y_i\)</span></p>
<p>对偶LP为： <span class="math inline">\(max: z&#39;=F(y_n-y_1)-\sum
x_i\)</span> <span class="math inline">\(\begin{cases} \forall (v,u) \in
E:y_u-y_v\leq cst_i+x_i \\ \forall i \in [1,m] ,x_{i}\geq
0\end{cases}\)</span></p>
<p>很明显，这里的<span class="math inline">\(y_n-y_1\)</span>就是最短路，整个对偶的LP的限制与题目相符。</p>
<p>令这对LP的最优解的值为<span class="math inline">\(t\)</span>,那么<span class="math display">\[F(y_n-y_1)-\sum x_i \leq t\]</span> <span class="math display">\[y_n-y_1\leq \frac{t+\sum x_i}{F}\]</span></p>
<p>因此我们只要求<span class="math inline">\(\frac{t+\sum
x_i}{F}\)</span>的最小值。只要在费用流每次增广的时候几下对应的<span class="math inline">\((flow,cst)\)</span>，每次询问在这些点里算最小值即可.</p>
<h1 id="代码">代码</h1>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> GCC optimize(3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rep(i,j,k) for(i=j;i&lt;=k;++i)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> dow(i,j,k) for(i=j;i&gt;=k;--i)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pr pair</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> mkp make_pair</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> fi first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> se second</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">60</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> M=N*N+N;</span><br><span class="line"><span class="keyword">namespace</span> MCMF&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">edge</span>&#123;</span><br><span class="line">        <span class="type">int</span> nxt,to,w,c;</span><br><span class="line">    &#125;e[M&lt;&lt;<span class="number">1</span>];</span><br><span class="line">    <span class="type">int</span> head[N],pos=<span class="number">1</span>,s,t,dis[N],pre[N],ep[N],flow,cst;</span><br><span class="line">    <span class="type">bool</span> vis[N];</span><br><span class="line">    vector&lt;pr&lt;<span class="type">int</span>,<span class="type">int</span>&gt; &gt;rec;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v,<span class="type">int</span> w,<span class="type">int</span> c)</span></span>&#123;</span><br><span class="line">        e[++pos]=(edge)&#123;head[u],v,w,c&#125;;head[u]=pos;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">spfa</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> i;<span class="built_in">rep</span>(i,<span class="number">1</span>,t)dis[i]=<span class="number">1</span>&lt;&lt;<span class="number">30</span>;</span><br><span class="line">        queue&lt;<span class="type">int</span>&gt;q;</span><br><span class="line">        <span class="built_in">memset</span>(vis,<span class="number">0</span>,<span class="built_in">sizeof</span>(vis));</span><br><span class="line">        <span class="built_in">rep</span>(i,<span class="number">1</span>,t)pre[i]=<span class="number">-1</span>;</span><br><span class="line">        dis[s]=<span class="number">0</span>;vis[s]=<span class="number">1</span>;</span><br><span class="line">        q.<span class="built_in">push</span>(s);</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="type">int</span> u=q.<span class="built_in">front</span>();q.<span class="built_in">pop</span>();vis[u]=<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(i=head[u];i;i=e[i].nxt)<span class="keyword">if</span>(e[i].w&gt;<span class="number">0</span> &amp;&amp; dis[e[i].to]&gt;dis[u]+e[i].c)&#123;</span><br><span class="line">                    dis[e[i].to]=dis[u]+e[i].c;ep[e[i].to]=i;</span><br><span class="line">                    pre[e[i].to]=u;<span class="keyword">if</span>(!vis[e[i].to])q.<span class="built_in">push</span>(e[i].to);vis[e[i].to]=<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dis[t]&lt;(<span class="number">1</span>&lt;&lt;<span class="number">30</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">EK</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> i;</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">spfa</span>())&#123;</span><br><span class="line">            <span class="type">int</span> f=<span class="number">1</span>&lt;&lt;<span class="number">30</span>;</span><br><span class="line">            <span class="keyword">for</span>(i=t;i!=s;i=pre[i])</span><br><span class="line">                f=<span class="built_in">min</span>(f,e[ep[i]].w);</span><br><span class="line">            flow+=f;cst+=f*dis[t];</span><br><span class="line">            <span class="keyword">for</span>(i=t;i!=s;i=pre[i])e[ep[i]].w-=f,e[ep[i]^<span class="number">1</span>].w+=f;</span><br><span class="line">            rec.<span class="built_in">push_back</span>(<span class="built_in">mkp</span>(flow,cst));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> n,m,u[M],v[M],w[M];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">solve</span><span class="params">(<span class="type">int</span> F)</span></span>&#123;</span><br><span class="line">    MCMF::pos=<span class="number">1</span>;</span><br><span class="line">    <span class="built_in">memset</span>(MCMF::head,<span class="number">0</span>,<span class="built_in">sizeof</span>(MCMF::head));</span><br><span class="line">    <span class="type">int</span> i,j;</span><br><span class="line">    <span class="built_in">rep</span>(i,<span class="number">1</span>,m)&#123;</span><br><span class="line">        MCMF::<span class="built_in">add</span>(u[i],v[i],<span class="number">1</span>,w[i]);</span><br><span class="line">        MCMF::<span class="built_in">add</span>(v[i],u[i],<span class="number">0</span>,-w[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    MCMF::s=n+<span class="number">1</span>;MCMF::t=n+<span class="number">2</span>;</span><br><span class="line">    MCMF::<span class="built_in">add</span>(n+<span class="number">1</span>,<span class="number">1</span>,F,<span class="number">0</span>);MCMF::<span class="built_in">add</span>(<span class="number">1</span>,n+<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">    MCMF::<span class="built_in">add</span>(n,n+<span class="number">2</span>,F,<span class="number">0</span>);MCMF::<span class="built_in">add</span>(n+<span class="number">2</span>,n,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">    MCMF::flow=<span class="number">0</span>;MCMF::cst=<span class="number">0</span>;</span><br><span class="line">    MCMF::<span class="built_in">EK</span>();</span><br><span class="line">    <span class="keyword">if</span>(MCMF::flow^F)<span class="keyword">return</span> <span class="number">1000000</span>;<span class="keyword">return</span> MCMF::cst;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;<span class="comment">//freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin);</span></span><br><span class="line">    ios::<span class="built_in">sync_with_stdio</span>(<span class="literal">false</span>);</span><br><span class="line">    <span class="type">int</span> i,j;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="built_in">rep</span>(i,<span class="number">1</span>,m)cin&gt;&gt;u[i]&gt;&gt;v[i]&gt;&gt;w[i];</span><br><span class="line">    <span class="type">int</span> q;</span><br><span class="line">    cin&gt;&gt;q;</span><br><span class="line">    <span class="built_in">solve</span>(m);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(q--)&#123;</span><br><span class="line">        <span class="type">int</span> xx;cin&gt;&gt;xx;</span><br><span class="line">        <span class="type">double</span> ans=<span class="number">1e9</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> v:MCMF::rec)ans=<span class="built_in">min</span>(ans,(<span class="number">1.0</span>*xx+v.se)/v.fi);</span><br><span class="line">        cout&lt;&lt;fixed;cout&lt;&lt;<span class="built_in">setprecision</span>(<span class="number">10</span>)&lt;&lt;ans&lt;&lt;<span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/11/lingp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/11/lingp/" class="post-title-link" itemprop="url">线性规划对偶</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-11 19:49:36" itemprop="dateCreated datePublished" datetime="2024-03-11T19:49:36+08:00">2024-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-12 00:16:25" itemprop="dateModified" datetime="2024-03-12T00:16:25+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="对偶问题">对偶问题</h1>
<p>考虑一个标准的线性规划问题：</p>
<p><span class="math inline">\(max:z=\sum\limits_{i=1}^{n}c_i\cdot
x_i\)</span></p>
<p>限制如下: <span class="math display">\[\begin{cases}
\sum\limits_{i=1}^{n}a_{1,i}\cdot x_i \leq b_1 \\
\sum\limits_{i=1}^{n}a_{2,i}\cdot x_i \leq b_2 \\
.....\\\sum\limits_{i=1}^{n}a_{m,i}\cdot x_i \leq
b_m\end{cases}\]</span></p>
<p><span class="math inline">\(\forall i \in [n] ,x_i \geq0\)</span></p>
<p>它的对偶形式是：</p>
<p><span class="math inline">\(min:z&#39;=\sum\limits_{j=1}^m b_j\cdot
y_j\)</span></p>
<p>限制：</p>
<p><span class="math display">\[\begin{cases}
\sum\limits_{j=1}^{m}a_{j,1}\cdot y_j \geq c_1 \\
\sum\limits_{j=1}^{m}a_{j,2}\cdot y_j \geq c_2 \\ .....\\
\sum\limits_{j=1}^{m}a_{j,n}\cdot y_j \geq c_n\end{cases}\]</span></p>
<p><span class="math inline">\(\forall j \in [m],y_j \geq 0\)</span></p>
<p>用矩阵的语言就是：</p>
<p>prime LP:</p>
<p><span class="math inline">\(max:z=\vec{c}^T\cdot \vec{x}\)</span></p>
<p><span class="math inline">\(A\cdot \vec{x} \preceq
\vec{b}\)</span></p>
<p><span class="math inline">\(\vec{x} \succeq 0\)</span></p>
<p>dual LP: <span class="math inline">\(min:z&#39;=\vec{b}^T\cdot
\vec{y}\)</span></p>
<p><span class="math inline">\(A^T\vec{y} \succeq \vec{c}\)</span></p>
<p><span class="math inline">\(\vec{y} \succeq\)</span></p>
<h1 id="weak-duality">weak duality</h1>
<p>上述两个LP,的任意一组feasible solution <span class="math inline">\(\hat{x},\hat{y}\)</span>,有<span class="math inline">\(\vec{c}^T\cdot \hat{x} \leq \vec{b}^T \cdot
\vec{y}\)</span>,i.e.最大化一定小于等于最小化.</p>
<p>证:</p>
<p>由于: <span class="math inline">\(A^T \cdot \hat{y} \succeq
\vec{c}\)</span>并且<span class="math inline">\(\hat{x} \succeq
0\)</span>,因而:<span class="math inline">\(\vec{c}^T\cdot \vec{x} \leq
(A^T\cdot \hat{y})^T \hat{x}=\hat{y}^T\cdot A \cdot \hat{x}\)</span></p>
<p>同样地：因为 <span class="math inline">\(A\cdot \hat{x} \preceq
\vec{b}\)</span>,<span class="math inline">\(\hat{y} \succeq
0\)</span>,因而 <span class="math inline">\(\vec{b}^T\cdot \hat{y} \geq
(A \cdot \hat{x})^T \cdot (\hat{y}^T)^T=(\hat{y}^T\cdot A \cdot
\hat{x})^T\)</span>,注意到 <span class="math inline">\(\hat{y}^T\cdot A
\cdot \hat{x}\)</span>是一个实数，所以 <span class="math inline">\((\hat{y}^T\cdot A \cdot \hat{x})^T=\hat{y}^T\cdot
A \cdot \hat{x}\)</span></p>
<p>因而：</p>
<p>${}^{T} ^{T} A ^{T} $</p>
<h1 id="互补松弛">互补松弛</h1>
<p>假设 <span class="math inline">\(\hat{x},\hat{y}\)</span>是两个LP的最优解，有<span class="math display">\[\vec{c}^T \cdot \hat{x} = \hat{y}^T\cdot A \cdot
\hat{x} = \vec{b}^T \cdot \hat{y}\]</span></p>
<p>我们对其变形： <span class="math display">\[\hat{y}^T\cdot A \cdot
\hat{x}-\vec{c}^T \cdot \hat{x} = 0\]</span> <span class="math display">\[(\hat{y}^T\cdot A-\vec{c}^T)\cdot \vec{x} =
0\]</span></p>
<p>由于 <span class="math inline">\(\hat{y}^T\cdot A-\vec{c}^T=(A^T\cdot
\hat{y}-\vec{c})^T\)</span>,i.e. <span class="math inline">\((A^T\cdot
\hat{y}-\vec{c})^T \cdot \hat{x} =0\)</span></p>
<p>写成代数形式：<span class="math inline">\(\sum\limits_{i=1}^n[({\sum\limits_{j=1}^ma_{j,i}\cdot
\hat{y}_j})-c_i]\cdot \hat{x}_i = 0\)</span></p>
<p>这说明了：如果<span class="math inline">\(x_i\)</span>非0，那么对偶问题中它对应的不等式一定取<code>=</code>，如果一个不等式不取<code>=</code>,那么对偶问题中这个不等式对应的变量一定为<code>0</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/07/pytorchreview2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/07/pytorchreview2/" class="post-title-link" itemprop="url">Pytorch巩固2 CNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-07 23:52:44 / Modified: 23:57:26" itemprop="dateCreated datePublished" datetime="2024-03-07T23:52:44+08:00">2024-03-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<p>这次任务是个18分类的问题， 除了网络结构不一样，其它和上一个基本一致.
只贴代码了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">word_cnt=<span class="number">29</span></span><br><span class="line"></span><br><span class="line">src=pd.read_csv(<span class="string">&quot;./data/data.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">        self.data=src[src.part==typ]</span><br><span class="line">        self.typ=typ</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        sen=[<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">        oht=np.zeros((<span class="number">15</span>,word_cnt))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="built_in">len</span>(sen),<span class="number">15</span>)):</span><br><span class="line">            oht[i,sen[i]-<span class="number">1</span>]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> torch.FloatTensor(oht),<span class="built_in">int</span>(self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br><span class="line">train_load=DataLoader(dataset=train_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_set=mydata(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">test_load=DataLoader(dataset=test_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">val_set=mydata(<span class="string">&quot;val&quot;</span>)</span><br><span class="line">val_load=DataLoader(dataset=val_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.h=<span class="number">50</span></span><br><span class="line">        self.mol=nn.Sequential(</span><br><span class="line">            nn.Conv1d(<span class="number">15</span>,self.h,<span class="number">5</span>,<span class="number">2</span>),nn.ELU(),</span><br><span class="line">            nn.Conv1d(self.h,self.h,<span class="number">5</span>,<span class="number">2</span>),nn.ELU(),</span><br><span class="line">            nn.Conv1d(self.h,self.h,<span class="number">5</span>,<span class="number">1</span>),nn.ELU(),</span><br><span class="line">        )</span><br><span class="line">        self.lin=nn.Linear(self.h,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y1=self.mol(x).squeeze(dim=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> self.lin(y1)</span><br><span class="line">mynn=Mol()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            out=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(out,tag):</span><br><span class="line">                x=x.argmax(dim=<span class="number">0</span>)</span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> x==y:</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率为&#123;:f&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>():</span><br><span class="line">    epoch=<span class="number">0</span></span><br><span class="line">    train_step=<span class="number">0</span></span><br><span class="line">    loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.Adam(mynn.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;批次:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            res_loss=loss_fn(output,tag)</span><br><span class="line">            res_loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            train_step+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss))</span><br><span class="line">        test_accuracy(test_load)</span><br><span class="line">        torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> exists(<span class="string">&quot;./model/final.pth&quot;</span>):</span><br><span class="line">    train_model()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br><span class="line">test_accuracy(val_load)</span><br></pre></td></tr></table></figure>
<p>输出:<code>准确率为0.707317</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/06/pytorchreview1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/06/pytorchreview1/" class="post-title-link" itemprop="url">Pytorch巩固1 one-hot 编码</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-06 10:22:34 / Modified: 11:15:33" itemprop="dateCreated datePublished" datetime="2024-03-06T10:22:34+08:00">2024-03-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<h1 id="one-hot">One-hot</h1>
<p>将句子分词后，生成一个向量 <span class="math inline">\(\vec{v}\)</span>,向量第 <span class="math inline">\(i\)</span>维为1当且仅当词<span class="math inline">\(i\)</span>出现过。 # 本次任务
数据集是csv文件，包括了单词转化为编码的形式，每个句子的标签（0，1二分类），train/val/test标注。
建立一个NN，本次重心不在backbone上，因此骨架只是一个单词数量映射到2的一个线性层。</p>
<h1 id="训练准备">训练准备</h1>
<p>由于每次训练的训练集数据都是批量拿取的，因此我们再复习下Dataset类和Dataloader的使用。</p>
<p>前置条件:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">word_num=<span class="number">8945</span></span><br></pre></td></tr></table></figure>
<h2 id="dataset-类">Dataset 类</h2>
<p>先调库: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br></pre></td></tr></table></figure> 读入数据: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src=pd.read_csv(<span class="string">&quot;data/数字化数据.csv&quot;</span>)</span><br></pre></td></tr></table></figure>
要继承Dataset类，需要写好构造函数<code>__init__()</code>,重写两个函数<code>__getitem__</code>与<code>__len__</code>。</p>
<p>构造函数可以记录一些基本的数据，记录好表示(比如train/val/test)
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">    self.typ=typ</span><br><span class="line">    self.data=src[src.part==typ]</span><br></pre></td></tr></table></figure> 这里存下了数据作用与对应的dataframe ### get_item
get_item会读入一个参数<code>idx</code>,函数要返回第<code>idx</code>个数据。</p>
<p>这里同时要对数据完成onehot编码，其中<code>-1</code>表示不认识这个词，忽略
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">    ts=torch.zeros(word_num,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    sentence=self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">    seq=[<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> sentence.split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> seq:</span><br><span class="line">        <span class="keyword">if</span> x!=-<span class="number">1</span>:</span><br><span class="line">            ts[x]=<span class="number">1</span></span><br><span class="line">    tag=<span class="built_in">int</span>(self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">    ts_tar=torch.zeros(<span class="number">2</span>,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    ts_tar[tag]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> ts,ts_tar</span><br></pre></td></tr></table></figure> ### len 返回数据集大小即可 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure></p>
<p>最后产生具体对象 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure> ## Dataloader 调的库在 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure>
本质是用Dataloader类创建一个对象,几个参数如下: 1. dataset
就是Dataset类构建出来的 2. batch_size 每次取出的个数 3.
shuffle最好设为<code>True</code> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_load=DataLoader(dataset=train_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
同样的还要构造好<code>val_load</code>,<code>test_load</code> #
神经网络骨架 不是这次的重点，只整一个线性层: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mol=nn.Sequential(</span><br><span class="line">            nn.Linear(word_num,<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_out = self.mol(x)</span><br><span class="line">        <span class="keyword">return</span> y_out</span><br><span class="line">mynn=Mol()</span><br></pre></td></tr></table></figure>
模型单个数据最后会输出一个shape为(2)的tensor，分别表示0类和1类的概率。</p>
<h1 id="测试准确率">测试准确率</h1>
<p>注意在测试时模型参数不能动，因此要设置 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            out=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(out,tag):</span><br><span class="line">                <span class="keyword">if</span> (x[<span class="number">0</span>]&gt;x[<span class="number">1</span>])==(y[<span class="number">0</span>]&gt;y[<span class="number">1</span>]):</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br></pre></td></tr></table></figure>
# 训练过程 ## 工具
损失函数设定为交叉熵，优化器为随机梯度下降，学习速率为<code>0.01</code>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.SGD(mynn.parameters(),lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
训练分多个批次(epoch),每个批次都会把所有数据训练一遍，每次训练先算当前神经网络输出，再算损失函数，然后反向传播梯度下降。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练批次数：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        sen,tag=data</span><br><span class="line">        output=mynn(sen)</span><br><span class="line">        res_loss=loss_fn(output,tag)</span><br><span class="line">        res_loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss.item()))</span><br><span class="line">        train_step+=<span class="number">1</span></span><br><span class="line">    test_accuracy(test_load)</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br></pre></td></tr></table></figure> ## 模型保存/读取 这次我只保存了模型参数： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
模型读取(要先创建好骨架)： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br></pre></td></tr></table></figure> ## 训练结果
<code>准确率为0.8693622448979592</code></p>
<h1 id="完整代码">完整代码</h1>
<p>后续放github上</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Meiqwq</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
