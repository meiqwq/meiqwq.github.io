<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A blog correlated with CS">
<meta property="og:type" content="website">
<meta property="og:title" content="Meiqwq&#39;s blog~">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Meiqwq&#39;s blog~">
<meta property="og:description" content="A blog correlated with CS">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Meiqwq">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Meiqwq's blog~</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Meiqwq's blog~</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meiqwq</p>
  <div class="site-description" itemprop="description">A blog correlated with CS</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/23/pytorch-base/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/23/pytorch-base/" class="post-title-link" itemprop="url">Pytorch 大杂烩</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-23 20:39:01" itemprop="dateCreated datePublished" datetime="2024-03-23T20:39:01+08:00">2024-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-25 00:42:22" itemprop="dateModified" datetime="2024-03-25T00:42:22+08:00">2024-03-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="tensor">tensor</h1>
<h2 id="flip">flip</h2>
<p>对某一个维度进行反转: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.flip(<span class="built_in">input</span>,dims)</span><br></pre></td></tr></table></figure> 返回反转完的tensor</p>
<p>dims是一个list or tuple</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(t)</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[2, 3, 4],</span></span><br><span class="line"><span class="string">        [5, 6, 7],</span></span><br><span class="line"><span class="string">        [1, 2, 3]]</span>)</span><br></pre></td></tr></table></figure> 再执行 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.flip(t,dims=(<span class="number">1</span>,))</span><br><span class="line"><span class="built_in">print</span>(t)</span><br></pre></td></tr></table></figure> 输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[4, 3, 2],</span></span><br><span class="line"><span class="string">        [7, 6, 5],</span></span><br><span class="line"><span class="string">        [3, 2, 1]]</span>)</span><br></pre></td></tr></table></figure> ## sum
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure> 可以直接返回t所有元素的和（以tensor的形式）。</p>
<p>当然还有别的用法 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">sum</span>(t,<span class="number">0</span>))</span><br></pre></td></tr></table></figure> 输出 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tensor</span>([ <span class="number">8</span>, <span class="number">11</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure>
对第dim维求和，返回tensor（少了第dim维）</p>
<h2 id="cat">cat</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>
<p>其中 tensors是tuple或者list
在dim维度拼接（也就是说第dim维度的东西会增多）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">t2=torch.LongTensor([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">9</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.cat([t1,t2],dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[2, 3, 4, 1, 1, 4],</span></span><br><span class="line"><span class="string">        [5, 6, 7, 5, 1, 4],</span></span><br><span class="line"><span class="string">        [1, 2, 3, 1, 9, 1]]</span>)</span><br></pre></td></tr></table></figure> 归纳，俩shape分别为<span class="math inline">\((a_1,a_2,...x_d,...a_n),(a_1,a_2,...y_d,...a_n)\)</span>的tensor在<code>torch.cat(dim=d)</code>后将会得到shape为<span class="math inline">\((a_1,a_2,...x_d+y_d,...a_n)\)</span></p>
<h2 id="stack">stack</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>
<p>其中tensors是列表或元组，在第dim维度堆叠 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.LongTensor([[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">t2=torch.LongTensor([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">9</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.stack([t1,t2],dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure> 输出
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[[2, 3, 4],</span></span><br><span class="line"><span class="string">         [1, 1, 4]]</span>,</span><br><span class="line"></span><br><span class="line">        <span class="string">[[5, 6, 7],</span></span><br><span class="line"><span class="string">         [5, 1, 4]]</span>,</span><br><span class="line"></span><br><span class="line">        <span class="string">[[1, 2, 3],</span></span><br><span class="line"><span class="string">         [1, 9, 1]]</span>])</span><br></pre></td></tr></table></figure></p>
<p>堆叠的所有tensor的shape一定要一致</p>
<p>归纳：将<span class="math inline">\(k\)</span>个tensor堆叠后，他们的shape将会在dim维多出一个<span class="math inline">\(k\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/21/tarski-lower-bound/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/21/tarski-lower-bound/" class="post-title-link" itemprop="url">Tarski 复杂度下界</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-21 00:25:07 / Modified: 10:09:17" itemprop="dateCreated datePublished" datetime="2024-03-21T00:25:07+08:00">2024-03-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="与主题无关的小命题">与主题无关的小命题</h1>
<h2 id="tarski-不动点存在性">Tarski 不动点存在性</h2>
<p>考虑<span class="math inline">\(f(1),f(f(1)),f(f(f(1)))....\)</span>一直单增，直到一个不动的</p>
<h2 id="寻找不动点上下确界是npc">寻找不动点上/下确界是NPC</h2>
<p>感觉文章的证明有点问题，还得再想想。</p>
<h1 id="如何证明一个问题的下界">如何证明一个问题的下界</h1>
<p>这里以寻找单增序列上的某个值举例，我们来证明这个问题的复杂度下界是
<span class="math inline">\(O(\log n)\)</span></p>
<p>现在假设有人向我提问，每次询问这个序列的某个元素，但实际上这个序列并不存在，可以是我实时构造来使得对方要消耗最多的询问次数，并且要满足序列单调增的限制，因此如果我每次都返回一个使可行区间更大的数，那么可行解范围最多除以2，因此我可以控制他至少问<span class="math inline">\(\Omega(\log n)\)</span></p>
<p>也就是说，我们以被提问者的角度，找到一个方案，使得无论询问者如何询问，在符合问题条件限制下，我们都能回答超过<span class="math inline">\(\Omega\)</span>次，所以这本质也是个构造问题. #
二维Tarski问题下界</p>
<h2 id="构造">构造</h2>
<p>我们的函数最后都张这个样子： <img src="construct.png">
（也就是有一条从最小元到最大元的路径）其它点指向它即可。
这样的函数一定是单调的，并且只有一个不动点。</p>
<p>这样，对于每次询问，如果我们回复左上或者右下，那么，我们就相当于排除了一块区域（后文将被排除的区域叫<code>forbidden area</code>）：
<img src="del.jpg"></p>
<p>如果对于某个询问点，我们回复了左上或右下，那么这个询问我们把它叫做<code>non-decisive query</code>,如果反之（即它在路径上）它将被叫做<code>decisive query</code>。</p>
<p>接下来，我们先呈现一个方案——具体如何回复，然后再验证这个方案的正确性（即会保证询问次数大于<span class="math inline">\(\Omega(\log^2 n)\)</span>）</p>
<h2 id="具体方案">具体方案</h2>
<ol type="1">
<li><p>如果面对一个询问<span class="math inline">\(q(x,y)\)</span>,如果<span class="math inline">\((x-1,y+1),(x+1,y-1)\)</span>都在<code>forbidden area</code>，这表明此刻我必须做一个<code>decisive query</code>的回复（不然路径就断了），至于回复哪个方向，我们选择一个方向，使得回复后的可行的路径的条数最多即可。</p></li>
<li><p>如果反之，一个询问<span class="math inline">\(q(x,y)\)</span>没有被<code>forbidden area</code>包夹，那么表明我们可以进行<code>non-decisve query</code>回复。但是具体回复哪个方向，我们要进行如下的分类讨论</p></li>
</ol>
<p><img src="fig.png"></p>
<h3 id="如果两侧的forbidden-area非常远">如果两侧的forbidden
area非常远</h3>
<p>i.e. a,b横坐标差大于<span class="math inline">\(\sqrt{n}\)</span>,那么选择一个方向，使得回复后剩余可行的路径条数最多。（称为<code>non-short query</code>）</p>
<h3 id="如果两侧-forbidden-area-很近">如果两侧 forbidden area 很近</h3>
<p>i.e. a,b横坐标差不大于<span class="math inline">\(\sqrt{n}\)</span>，那么我们回复一个与边界(a,b)更远的方向。(称为<code>short query</code>)</p>
<p><img src="q.jpg"> ## 方案正确性证明 首先我们定义一个势函数<span class="math inline">\(L(t)\)</span>表示第<span class="math inline">\(t\)</span>次询问时，可行路径方案数的对数。因此<span class="math display">\[L(1)=\log(\binom{2n}{n})=\log((2n)!)-2\log(n!)\]</span>
由斯特林公式：<span class="math display">\[\log(n!) \sim
\frac{1}{2}\cdot \log n+n(\log n-1)\]</span></p>
<p>因此<span class="math display">\[L(1) \sim \frac{1}{2}\cdot \log
2n+2n(\log 2n-1)-\log n -2n(\log n-1)\]</span></p>
<p><span class="math display">\[=\log2 \cdot n + o(n)\sim
\Theta(n)\]</span></p>
<p>( 好像利用二项式展开再夹逼更简单</p>
<p>如果，我们遇到迫不得已回复<code>decisive query</code></p>
<p><img src="dec.jpg">,我们选择<code>a,b,c,d</code>中的某一个回复，先选<span class="math inline">\(a+b\)</span>,<span class="math inline">\(c+d\)</span>的较大者，再选里面的更大的，那么<span class="math inline">\(L(t+1)\geq \frac{1}{2}L(t)-1\)</span></p>
<p>如果可以回复一个<code>non decisve query</code>：</p>
<ol type="1">
<li><code>non-short query</code></li>
</ol>
<p><img src="far.jpg"> 方案数变为原来的<span class="math inline">\(\frac{1}{2}(1-\frac{1}{\sqrt{n}})\geq
\frac{1}{4}\)</span>,因此<span class="math inline">\(L(t+1)\geq
L(t)-2\)</span></p>
<ol start="2" type="1">
<li><code>short query</code></li>
</ol>
<p>假设两侧距离是<span class="math inline">\(d\)</span>,那么方案书变为原来的<span class="math inline">\(\frac{1}{2}(1-\frac{1}{d})\)</span>那么<span class="math display">\[L(t+1)\geq
\log(\frac{1}{2}(1-\frac{1}{d}))+L(t)\sim L(t)-\frac{1}{d-1}\geq
L(t)-d\]</span></p>
<p>因此<span class="math inline">\(L(t+1)\geq L(t)-\sqrt{n}\log
n\)</span></p>
<p>综上，我们发现，<span class="math inline">\(L\)</span>每次要么砍半，要么少一个<span class="math inline">\(o(n)\)</span>阶的常数，因此下界至少是<span class="math inline">\(\Omega(\log n)\)</span> 但是我们的目标是<span class="math inline">\(\Omega(\log^2
n)\)</span>,于是，接下来我们证明两件事：</p>
<ol type="1">
<li>如果对于一个<code>decisve query</code>,如果其它<code>decisve query</code>和他距离都超过<span class="math inline">\(\sqrt{n}\)</span>,那么这个query被称为<code>effective query</code>。</li>
</ol>
<p>如果总询问次数是<span class="math inline">\(O(\log^2
n)\)</span>,那么至少有<span class="math inline">\(\Omega(\log
n)\)</span>个<code>effective query</code></p>
<ol start="2" type="1">
<li>每个<code>effective query</code>都能对应<span class="math inline">\(\Omega(\log
n)\)</span>个<code>non-decisve query</code></li>
</ol>
<h3 id="section">1</h3>
<p>注意到<span class="math inline">\(L\)</span>一开始是<span class="math inline">\(n\)</span>,然后要么砍半，要么<span class="math inline">\(-\sqrt{n}\log n\)</span>,而且在<span class="math inline">\(\log^2(n)\)</span>以内就衰减到1了，假设这<span class="math inline">\(\log^2 n\)</span>次操作中有<span class="math inline">\(x\)</span>次砍半，那么<span class="math inline">\(\log(n-x\sqrt{n}\log n)\leq
x\)</span>可以发现这个不等式的一个必要的解是<span class="math inline">\(x\geq \log(n)\)</span></p>
<h3 id="section-1">2</h3>
<p>原文是归纳的，这里先感性理解一下，左上右下的边界最多是一半一半砍的，砍出一个<code>decisve query</code>肯定要<span class="math inline">\(\log(n)\)</span>次</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/13/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/13/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A2/" class="post-title-link" itemprop="url">复杂度理论作业2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-13 20:32:59" itemprop="dateCreated datePublished" datetime="2024-03-13T20:32:59+08:00">2024-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-19 00:27:48" itemprop="dateModified" datetime="2024-03-19T00:27:48+08:00">2024-03-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="section">1.2</h1>
<p>问题：对于Steiner Tree 问题，证明，存在一个常数<span class="math inline">\(c\)</span>,使得对于Steiner Tree 问题，没有<span class="math inline">\(c\log |T|\)</span>-approximation算法，除非<span class="math inline">\(P=NP\)</span></p>
<p>证： 先证NPC： 1. NP-HARD：考虑从un-weighted set
cover归约，对于一个set
cover，将根节点向每个集合连一条边权为1的有向边，每个集合再向自己的元素连0权有向边，目标集合设定为所有元素节点。
2. NPC:显然这是NP的</p>
<p>按照课本<code>定理1.14</code>(如果存在一个<span class="math inline">\(c\)</span>,使得如果存在一个set cover的<span class="math inline">\(c\ln n\)</span>算法，那么<span class="math inline">\(P=NP\)</span>)得证</p>
<h1 id="section-1">1.3</h1>
<h2 id="a">a</h2>
<ol type="1">
<li>考虑每个环，对每个点的入度和出度都增加1，因此最终所有点的出度和入度都是一样的，因此是欧拉图。</li>
<li>由于是欧拉图，因此存在一个遍历所有边的环路，故而遍历了所有点，因此图是强连通的。</li>
</ol>
<p>综上，得到的子图是一个强连通欧拉图。</p>
<h2 id="b">b</h2>
<p>设第 <span class="math inline">\(i\)</span> 轮后，图上还有 <span class="math inline">\(n_i\)</span>个节点。第<span class="math inline">\(i\)</span>轮选择的最小平均值为<span class="math inline">\(w_i\)</span>,令最优解为 <span class="math inline">\(OPT\)</span></p>
<p>考虑最优解形成的环： <img src="loop.jpg" alt="loop"> 假设第<span class="math inline">\(i\)</span>轮开始前是如图的，蓝色的点是已经被删去的，由三角形不等式，设这个环的和为<span class="math inline">\(OPT&#39;\)</span>,那么一定有<span class="math inline">\(OPT&#39; \leq OPT\)</span> 因此<span class="math inline">\(w_i \leq \frac{OPT&#39;}{n_i} \leq
\frac{OPT}{n_i}\)</span>,第<span class="math inline">\(i\)</span>轮的贡献为<span class="math inline">\(w_i\cdot (n_i-n_{i+1}+1)\)</span>,因而总贡献<span class="math display">\[\sum (n_i-n_{i+1}+1)\cdot w_i \leq
\sum\frac{n_i-n_{i+1}+1}{n_i}\cdot OPT\]</span></p>
<p>注意到<span class="math inline">\(\sum\frac{n_i-n_{i+1}}{n_i} \leq
H_n\)</span>并且<span class="math inline">\(\sum\frac{1}{n_i} \leq
H_n\)</span>，因此总贡献小于等于<span class="math inline">\(2H_n\cdot
OPT\)</span></p>
<h1 id="section-2">1.5</h1>
<p>对于无向图带权set cover问题</p>
<ol type="1">
<li>列出下列LP:</li>
</ol>
<p>目标：<span class="math inline">\(min:z=\sum\limits_{i=1}^{n}w_i
\cdot x_i\)</span></p>
<p>subject to:</p>
<p><span class="math inline">\(\forall (u,v) \in E:x_u+x_v
\geq1\)</span> <span class="math inline">\(x_i \geq 0\)</span>
证明，对于该问题的extreme point <span class="math inline">\(x*\)</span>,<span class="math inline">\(x*_i \in
\{0,\frac{1}{2},1 \}\)</span> 证： 用反证，如果存在一个extreme
point,其中有不在<span class="math inline">\(\{0,1,\frac{1}{2}\}\)</span>中的<span class="math inline">\(x\)</span>,我们直接对所有小于<span class="math inline">\(\frac{1}{2}\)</span>且不是0的值减去<span class="math inline">\(\epsilon\)</span>,对所有大于<span class="math inline">\(\frac{1}{2}\)</span>且不是1的值加上<span class="math inline">\(\epsilon\)</span>,构造出一个新的<span class="math inline">\(y_1\)</span>,然后再对其中有不在<span class="math inline">\(\{0,1,\frac{1}{2}\}\)</span>中的<span class="math inline">\(x\)</span>,我们直接对所有小于<span class="math inline">\(\frac{1}{2}\)</span>且不是0的值+<span class="math inline">\(\epsilon\)</span>,对所有大于<span class="math inline">\(\frac{1}{2}\)</span>且不是1的值-<span class="math inline">\(\epsilon\)</span>，得到<span class="math inline">\(y_2\)</span>,可以发现<span class="math inline">\(\frac{y_1+y_2}{2}=x^*\)</span>,与<span class="math inline">\(x*\)</span>是extreme point矛盾</p>
<ol start="2" type="1">
<li>构造一个<span class="math inline">\(\frac{3}{2}\)</span>-approximation
算法求解平面图set-cover</li>
</ol>
<p>首先多项式时间跑一遍上面的线性规划，如果一个点的赋值是0或1，那就选或不选，剩下的点都是<span class="math inline">\(\frac{1}{2}\)</span>的点，它们连的点一定是<span class="math inline">\(\frac{1}{2}\)</span>或者<span class="math inline">\(1\)</span>的点，因此，我们考虑所有<span class="math inline">\(\frac{1}{2}\)</span>的点的导出子图<span class="math inline">\(G&#39;\)</span>(显然<span class="math inline">\(G&#39;\)</span>也是平面图),我们的目标是把<span class="math inline">\(G&#39;\)</span>里的所有点都改成0或1，并且只要满足在<span class="math inline">\(G&#39;\)</span>里没有0和0共边即可。</p>
<p>对<span class="math inline">\(G&#39;\)</span>跑四染色(可以多项式)，设四个部分颜色的和分别为<span class="math inline">\(a,b,c,d\)</span>,WLOG. 设<span class="math inline">\(a\leq b\leq c\leq d\)</span>,让<span class="math inline">\(a,b,c\)</span>里面的点取1，<span class="math inline">\(d\)</span>的取0。这样我们就得到了<span class="math inline">\(\frac{3}{2}-approximation\)</span></p>
<p>正确性：首先肯定没有00共边。</p>
<p>其次，我们设线性规划的最优解是<span class="math inline">\(x^*\)</span>,rounding后的解是<span class="math inline">\(\hat{x}\)</span>,<span class="math inline">\(G&#39;\)</span>的点集为<span class="math inline">\(V&#39;\)</span>,那么rounding后的答案为<span class="math display">\[\sum\limits_{v \notin V&#39;}\hat{x}_v \cdot
w_v+\sum\limits_{v\in V&#39;}\hat{x}_v\cdot w_v=\sum\limits_{v\notin
V&#39;}x^*_v\cdot w_v+(a+b+c)\]</span>,而我们可以发现，<span class="math inline">\(a+b+c\leq 3d\)</span>,因此<span class="math display">\[a+b+c= (a+b+c+d)\frac{a+b+c}{a+b+c+d}\leq
(a+b+c+d)\frac{1}{1+\frac{d}{a+b+c}}\leq
(a+b+c+d)\frac{1}{1+\frac{1}{3}}=\frac{3}{4}(a+b+c+d)\]</span></p>
<p>故<span class="math inline">\(\sum\limits_{v\notin V&#39;}x^*_v\cdot
w_v+(a+b+c) \leq \sum\limits_{v\notin V&#39;}x^*_v\cdot w_v+\frac{3}{2}
\sum\limits_{v\in V&#39;}x^*_v\cdot w_v \leq \frac{3}{2}LP \leq
\frac{3}{2}OPT\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/12/pytorchreview3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/pytorchreview3/" class="post-title-link" itemprop="url">pytorch巩固3 RNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-12 17:08:50 / Modified: 17:21:01" itemprop="dateCreated datePublished" datetime="2024-03-12T17:08:50+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<h1 id="rnn-网络结构">RNN 网络结构</h1>
<figure>
<img src="rnn.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>先把句子分词，然后从前往后扫每一个词，每次把当前的词和之前的记忆扔到RNN_cell里。这个结构是合理的，因为它模拟了人的阅读方式。</p>
<p>如果是翻译任务的话只要所有的输出即可.</p>
<h2 id="代码">代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):<span class="comment"># 输入一个(batch_size,词数)的一个tensor,输出(batch_size,18)的tensor</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.emb=nn.Embedding(<span class="number">30</span>,<span class="number">50</span>,<span class="number">0</span>)</span><br><span class="line">        self.rnn=nn.RNNCell(<span class="number">50</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc1=nn.Linear(<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">100</span>,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        b=x.shape[<span class="number">0</span>]</span><br><span class="line">        out=torch.zeros((b,<span class="number">100</span>))</span><br><span class="line">        embbed=self.emb(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">            out=self.rnn(embbed[:,i,:,],out)</span><br><span class="line">        out=F.relu(self.fc1(F.dropout(out,<span class="number">0.5</span>)))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(F.dropout(out,<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>
<h1 id="总体实现">总体实现</h1>
<p>这次转换函数在dataset外部实现了，所以还是放一下全部代码 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">src=pd.read_csv(<span class="string">&quot;./data/data.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">        self.data=src[src.part==typ]</span><br><span class="line">        self.typ=typ</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>],self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_tensor</span>(<span class="params">data</span>):</span><br><span class="line">    N=<span class="built_in">len</span>(data)</span><br><span class="line">    t1=np.zeros((N,<span class="number">15</span>))</span><br><span class="line">    t2=np.zeros((N))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        x,y=data[i]</span><br><span class="line">        x=x.split(<span class="string">&#x27;,&#x27;</span>)+[<span class="number">0</span>]*<span class="number">15</span></span><br><span class="line">        x=x[:<span class="number">15</span>]</span><br><span class="line">        x=[<span class="built_in">int</span>(xx) <span class="keyword">for</span> xx <span class="keyword">in</span> x]</span><br><span class="line">        t1[i]=x</span><br><span class="line">        t2[i]=<span class="built_in">int</span>(y)</span><br><span class="line">    <span class="keyword">return</span> torch.LongTensor(t1),torch.LongTensor(t2)</span><br><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br><span class="line">train_load=DataLoader(dataset=train_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line">test_set=mydata(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">test_load=DataLoader(dataset=test_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line">val_set=mydata(<span class="string">&quot;val&quot;</span>)</span><br><span class="line">val_load=DataLoader(dataset=val_set,batch_size=<span class="number">100</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>,collate_fn=to_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.emb=nn.Embedding(<span class="number">30</span>,<span class="number">50</span>,<span class="number">0</span>)</span><br><span class="line">        self.rnn=nn.RNNCell(<span class="number">50</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc1=nn.Linear(<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">100</span>,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        b=x.shape[<span class="number">0</span>]</span><br><span class="line">        out=torch.zeros((b,<span class="number">100</span>))</span><br><span class="line">        embbed=self.emb(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">            out=self.rnn(embbed[:,i,:,],out)</span><br><span class="line">        out=F.relu(self.fc1(F.dropout(out,<span class="number">0.5</span>)))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(F.dropout(out,<span class="number">0.5</span>))</span><br><span class="line">mynn=Mol()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(output,tag):</span><br><span class="line">                x=x.argmax(dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> x==y:</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>():</span><br><span class="line">    epoch=<span class="number">0</span></span><br><span class="line">    train_step=<span class="number">0</span></span><br><span class="line">    loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.Adam(mynn.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;批次:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            res_loss=loss_fn(output,tag)</span><br><span class="line">            res_loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            train_step+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss))</span><br><span class="line">        test_accuracy(test_load)</span><br><span class="line">        torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> exists(<span class="string">&quot;./model/final.pth&quot;</span>):</span><br><span class="line">    train_model()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br><span class="line">test_accuracy(val_load)</span><br></pre></td></tr></table></figure>
输出: <code>准确率:0.692</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/12/CF1307G/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/CF1307G/" class="post-title-link" itemprop="url">CF1307G</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-12 00:19:50 / Modified: 00:44:34" itemprop="dateCreated datePublished" datetime="2024-03-12T00:19:50+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://codeforces.com/contest/1307/problem/G">题目链接</a></p>
<h1 id="题意">题意：</h1>
<p>给出一个 <span class="math inline">\(n\)</span> 个点 <span class="math inline">\(m\)</span>
条边的<strong>有向图</strong>，每条边有边权 <span class="math inline">\(w_i\)</span> 。</p>
<p>有 <span class="math inline">\(Q\)</span> 次询问，每次询问给出一个
<span class="math inline">\(x\)</span> 。你可以把一条边修改成 <span class="math inline">\(w_i+a_i\)</span> （<span class="math inline">\(a_i\)</span>
<strong>不一定</strong>是整数），不过需要保证 <span class="math inline">\(a_i \geq 0\)</span> 且 <span class="math inline">\(\sum a_i \leq x\)</span> 。</p>
<p>你要通过修改边权使得从 <span class="math inline">\(1\)</span> 到
<span class="math inline">\(n\)</span>
的最短路径尽可能长，每次询问之间<strong>独立</strong>。</p>
<p>数据保证至少存在一条从 <span class="math inline">\(1\)</span> 到
<span class="math inline">\(n\)</span> 的路径，无重边自环。</p>
<p>输出答案和标准答案的相对误差或绝对误差应不超过 <span class="math inline">\(10^{-6}\)</span> 。(翻译来自luogu)</p>
<h1 id="分析">分析</h1>
<p>先观察一下费用流的LP：</p>
<p><span class="math inline">\(min:z=\sum flow_i \cdot
cst_i\)</span></p>
<p>限制:</p>
$
<span class="math display">\[\begin{cases} u=1时:\sum\limits_{i \in
out_u}-flow_i=-F\\ u\in[2,n-1]: \sum\limits_{i \in
out_u}-flow_i+\sum\limits_{i\in in_u}flow_i=0 \\ u=n时:\sum\limits_{i
\in in_u}flow_i=F \\ flow_1 \leq cap_1 \\ flow_2 \leq cap_2 \\ ...... \\
flow_m \leq cap_m \\ \forall i \in [m],flow_i \geq 0
\end{cases}\]</span>
<p>$</p>
<p>转对偶LP：</p>
<p><span class="math inline">\(max:
z=F(y_n-y_1)+\sum\limits_{i=1}^{m}y_{n+i}\cdot cap_i\)</span></p>
<p>限制:</p>
<p><span class="math inline">\(\begin{cases} \forall (v,u) \in
E:y_u-y_v+y_{n+i} \leq cst_i \\ \forall i \in [n+1,n+m] ,y_{i}\leq
0\end{cases}\)</span></p>
<p>因而令<span class="math inline">\(\forall i \in [n+1,n+m],
x_{i-n}=-y_i\)</span></p>
<p>对偶LP为： <span class="math inline">\(max: z&#39;=F(y_n-y_1)-\sum
x_i\)</span> <span class="math inline">\(\begin{cases} \forall (v,u) \in
E:y_u-y_v\leq cst_i+x_i \\ \forall i \in [1,m] ,x_{i}\geq
0\end{cases}\)</span></p>
<p>很明显，这里的<span class="math inline">\(y_n-y_1\)</span>就是最短路，整个对偶的LP的限制与题目相符。</p>
<p>令这对LP的最优解的值为<span class="math inline">\(t\)</span>,那么<span class="math display">\[F(y_n-y_1)-\sum x_i \leq t\]</span> <span class="math display">\[y_n-y_1\leq \frac{t+\sum x_i}{F}\]</span></p>
<p>因此我们只要求<span class="math inline">\(\frac{t+\sum
x_i}{F}\)</span>的最小值。只要在费用流每次增广的时候几下对应的<span class="math inline">\((flow,cst)\)</span>，每次询问在这些点里算最小值即可.</p>
<h1 id="代码">代码</h1>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> GCC optimize(3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rep(i,j,k) for(i=j;i&lt;=k;++i)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> dow(i,j,k) for(i=j;i&gt;=k;--i)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pr pair</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> mkp make_pair</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> fi first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> se second</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">60</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> M=N*N+N;</span><br><span class="line"><span class="keyword">namespace</span> MCMF&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">edge</span>&#123;</span><br><span class="line">        <span class="type">int</span> nxt,to,w,c;</span><br><span class="line">    &#125;e[M&lt;&lt;<span class="number">1</span>];</span><br><span class="line">    <span class="type">int</span> head[N],pos=<span class="number">1</span>,s,t,dis[N],pre[N],ep[N],flow,cst;</span><br><span class="line">    <span class="type">bool</span> vis[N];</span><br><span class="line">    vector&lt;pr&lt;<span class="type">int</span>,<span class="type">int</span>&gt; &gt;rec;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v,<span class="type">int</span> w,<span class="type">int</span> c)</span></span>&#123;</span><br><span class="line">        e[++pos]=(edge)&#123;head[u],v,w,c&#125;;head[u]=pos;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">spfa</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> i;<span class="built_in">rep</span>(i,<span class="number">1</span>,t)dis[i]=<span class="number">1</span>&lt;&lt;<span class="number">30</span>;</span><br><span class="line">        queue&lt;<span class="type">int</span>&gt;q;</span><br><span class="line">        <span class="built_in">memset</span>(vis,<span class="number">0</span>,<span class="built_in">sizeof</span>(vis));</span><br><span class="line">        <span class="built_in">rep</span>(i,<span class="number">1</span>,t)pre[i]=<span class="number">-1</span>;</span><br><span class="line">        dis[s]=<span class="number">0</span>;vis[s]=<span class="number">1</span>;</span><br><span class="line">        q.<span class="built_in">push</span>(s);</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="type">int</span> u=q.<span class="built_in">front</span>();q.<span class="built_in">pop</span>();vis[u]=<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(i=head[u];i;i=e[i].nxt)<span class="keyword">if</span>(e[i].w&gt;<span class="number">0</span> &amp;&amp; dis[e[i].to]&gt;dis[u]+e[i].c)&#123;</span><br><span class="line">                    dis[e[i].to]=dis[u]+e[i].c;ep[e[i].to]=i;</span><br><span class="line">                    pre[e[i].to]=u;<span class="keyword">if</span>(!vis[e[i].to])q.<span class="built_in">push</span>(e[i].to);vis[e[i].to]=<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dis[t]&lt;(<span class="number">1</span>&lt;&lt;<span class="number">30</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">EK</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> i;</span><br><span class="line">        <span class="keyword">while</span>(<span class="built_in">spfa</span>())&#123;</span><br><span class="line">            <span class="type">int</span> f=<span class="number">1</span>&lt;&lt;<span class="number">30</span>;</span><br><span class="line">            <span class="keyword">for</span>(i=t;i!=s;i=pre[i])</span><br><span class="line">                f=<span class="built_in">min</span>(f,e[ep[i]].w);</span><br><span class="line">            flow+=f;cst+=f*dis[t];</span><br><span class="line">            <span class="keyword">for</span>(i=t;i!=s;i=pre[i])e[ep[i]].w-=f,e[ep[i]^<span class="number">1</span>].w+=f;</span><br><span class="line">            rec.<span class="built_in">push_back</span>(<span class="built_in">mkp</span>(flow,cst));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> n,m,u[M],v[M],w[M];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">solve</span><span class="params">(<span class="type">int</span> F)</span></span>&#123;</span><br><span class="line">    MCMF::pos=<span class="number">1</span>;</span><br><span class="line">    <span class="built_in">memset</span>(MCMF::head,<span class="number">0</span>,<span class="built_in">sizeof</span>(MCMF::head));</span><br><span class="line">    <span class="type">int</span> i,j;</span><br><span class="line">    <span class="built_in">rep</span>(i,<span class="number">1</span>,m)&#123;</span><br><span class="line">        MCMF::<span class="built_in">add</span>(u[i],v[i],<span class="number">1</span>,w[i]);</span><br><span class="line">        MCMF::<span class="built_in">add</span>(v[i],u[i],<span class="number">0</span>,-w[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    MCMF::s=n+<span class="number">1</span>;MCMF::t=n+<span class="number">2</span>;</span><br><span class="line">    MCMF::<span class="built_in">add</span>(n+<span class="number">1</span>,<span class="number">1</span>,F,<span class="number">0</span>);MCMF::<span class="built_in">add</span>(<span class="number">1</span>,n+<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">    MCMF::<span class="built_in">add</span>(n,n+<span class="number">2</span>,F,<span class="number">0</span>);MCMF::<span class="built_in">add</span>(n+<span class="number">2</span>,n,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">    MCMF::flow=<span class="number">0</span>;MCMF::cst=<span class="number">0</span>;</span><br><span class="line">    MCMF::<span class="built_in">EK</span>();</span><br><span class="line">    <span class="keyword">if</span>(MCMF::flow^F)<span class="keyword">return</span> <span class="number">1000000</span>;<span class="keyword">return</span> MCMF::cst;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;<span class="comment">//freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin);</span></span><br><span class="line">    ios::<span class="built_in">sync_with_stdio</span>(<span class="literal">false</span>);</span><br><span class="line">    <span class="type">int</span> i,j;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="built_in">rep</span>(i,<span class="number">1</span>,m)cin&gt;&gt;u[i]&gt;&gt;v[i]&gt;&gt;w[i];</span><br><span class="line">    <span class="type">int</span> q;</span><br><span class="line">    cin&gt;&gt;q;</span><br><span class="line">    <span class="built_in">solve</span>(m);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(q--)&#123;</span><br><span class="line">        <span class="type">int</span> xx;cin&gt;&gt;xx;</span><br><span class="line">        <span class="type">double</span> ans=<span class="number">1e9</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> v:MCMF::rec)ans=<span class="built_in">min</span>(ans,(<span class="number">1.0</span>*xx+v.se)/v.fi);</span><br><span class="line">        cout&lt;&lt;fixed;cout&lt;&lt;<span class="built_in">setprecision</span>(<span class="number">10</span>)&lt;&lt;ans&lt;&lt;<span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/11/lingp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/11/lingp/" class="post-title-link" itemprop="url">线性规划对偶</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-11 19:49:36" itemprop="dateCreated datePublished" datetime="2024-03-11T19:49:36+08:00">2024-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-12 00:16:25" itemprop="dateModified" datetime="2024-03-12T00:16:25+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="对偶问题">对偶问题</h1>
<p>考虑一个标准的线性规划问题：</p>
<p><span class="math inline">\(max:z=\sum\limits_{i=1}^{n}c_i\cdot
x_i\)</span></p>
<p>限制如下: <span class="math display">\[\begin{cases}
\sum\limits_{i=1}^{n}a_{1,i}\cdot x_i \leq b_1 \\
\sum\limits_{i=1}^{n}a_{2,i}\cdot x_i \leq b_2 \\
.....\\\sum\limits_{i=1}^{n}a_{m,i}\cdot x_i \leq
b_m\end{cases}\]</span></p>
<p><span class="math inline">\(\forall i \in [n] ,x_i \geq0\)</span></p>
<p>它的对偶形式是：</p>
<p><span class="math inline">\(min:z&#39;=\sum\limits_{j=1}^m b_j\cdot
y_j\)</span></p>
<p>限制：</p>
<p><span class="math display">\[\begin{cases}
\sum\limits_{j=1}^{m}a_{j,1}\cdot y_j \geq c_1 \\
\sum\limits_{j=1}^{m}a_{j,2}\cdot y_j \geq c_2 \\ .....\\
\sum\limits_{j=1}^{m}a_{j,n}\cdot y_j \geq c_n\end{cases}\]</span></p>
<p><span class="math inline">\(\forall j \in [m],y_j \geq 0\)</span></p>
<p>用矩阵的语言就是：</p>
<p>prime LP:</p>
<p><span class="math inline">\(max:z=\vec{c}^T\cdot \vec{x}\)</span></p>
<p><span class="math inline">\(A\cdot \vec{x} \preceq
\vec{b}\)</span></p>
<p><span class="math inline">\(\vec{x} \succeq 0\)</span></p>
<p>dual LP: <span class="math inline">\(min:z&#39;=\vec{b}^T\cdot
\vec{y}\)</span></p>
<p><span class="math inline">\(A^T\vec{y} \succeq \vec{c}\)</span></p>
<p><span class="math inline">\(\vec{y} \succeq\)</span></p>
<h1 id="weak-duality">weak duality</h1>
<p>上述两个LP,的任意一组feasible solution <span class="math inline">\(\hat{x},\hat{y}\)</span>,有<span class="math inline">\(\vec{c}^T\cdot \hat{x} \leq \vec{b}^T \cdot
\vec{y}\)</span>,i.e.最大化一定小于等于最小化.</p>
<p>证:</p>
<p>由于: <span class="math inline">\(A^T \cdot \hat{y} \succeq
\vec{c}\)</span>并且<span class="math inline">\(\hat{x} \succeq
0\)</span>,因而:<span class="math inline">\(\vec{c}^T\cdot \vec{x} \leq
(A^T\cdot \hat{y})^T \hat{x}=\hat{y}^T\cdot A \cdot \hat{x}\)</span></p>
<p>同样地：因为 <span class="math inline">\(A\cdot \hat{x} \preceq
\vec{b}\)</span>,<span class="math inline">\(\hat{y} \succeq
0\)</span>,因而 <span class="math inline">\(\vec{b}^T\cdot \hat{y} \geq
(A \cdot \hat{x})^T \cdot (\hat{y}^T)^T=(\hat{y}^T\cdot A \cdot
\hat{x})^T\)</span>,注意到 <span class="math inline">\(\hat{y}^T\cdot A
\cdot \hat{x}\)</span>是一个实数，所以 <span class="math inline">\((\hat{y}^T\cdot A \cdot \hat{x})^T=\hat{y}^T\cdot
A \cdot \hat{x}\)</span></p>
<p>因而：</p>
<p>${}^{T} ^{T} A ^{T} $</p>
<h1 id="互补松弛">互补松弛</h1>
<p>假设 <span class="math inline">\(\hat{x},\hat{y}\)</span>是两个LP的最优解，有<span class="math display">\[\vec{c}^T \cdot \hat{x} = \hat{y}^T\cdot A \cdot
\hat{x} = \vec{b}^T \cdot \hat{y}\]</span></p>
<p>我们对其变形： <span class="math display">\[\hat{y}^T\cdot A \cdot
\hat{x}-\vec{c}^T \cdot \hat{x} = 0\]</span> <span class="math display">\[(\hat{y}^T\cdot A-\vec{c}^T)\cdot \vec{x} =
0\]</span></p>
<p>由于 <span class="math inline">\(\hat{y}^T\cdot A-\vec{c}^T=(A^T\cdot
\hat{y}-\vec{c})^T\)</span>,i.e. <span class="math inline">\((A^T\cdot
\hat{y}-\vec{c})^T \cdot \hat{x} =0\)</span></p>
<p>写成代数形式：<span class="math inline">\(\sum\limits_{i=1}^n[({\sum\limits_{j=1}^ma_{j,i}\cdot
\hat{y}_j})-c_i]\cdot \hat{x}_i = 0\)</span></p>
<p>这说明了：如果<span class="math inline">\(x_i\)</span>非0，那么对偶问题中它对应的不等式一定取<code>=</code>，如果一个不等式不取<code>=</code>,那么对偶问题中这个不等式对应的变量一定为<code>0</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/07/pytorchreview2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/07/pytorchreview2/" class="post-title-link" itemprop="url">Pytorch巩固2 CNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-07 23:52:44 / Modified: 23:57:26" itemprop="dateCreated datePublished" datetime="2024-03-07T23:52:44+08:00">2024-03-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<p>这次任务是个18分类的问题， 除了网络结构不一样，其它和上一个基本一致.
只贴代码了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">word_cnt=<span class="number">29</span></span><br><span class="line"></span><br><span class="line">src=pd.read_csv(<span class="string">&quot;./data/data.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">        self.data=src[src.part==typ]</span><br><span class="line">        self.typ=typ</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        sen=[<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">        oht=np.zeros((<span class="number">15</span>,word_cnt))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="built_in">len</span>(sen),<span class="number">15</span>)):</span><br><span class="line">            oht[i,sen[i]-<span class="number">1</span>]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> torch.FloatTensor(oht),<span class="built_in">int</span>(self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br><span class="line">train_load=DataLoader(dataset=train_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_set=mydata(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">test_load=DataLoader(dataset=test_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">val_set=mydata(<span class="string">&quot;val&quot;</span>)</span><br><span class="line">val_load=DataLoader(dataset=val_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.h=<span class="number">50</span></span><br><span class="line">        self.mol=nn.Sequential(</span><br><span class="line">            nn.Conv1d(<span class="number">15</span>,self.h,<span class="number">5</span>,<span class="number">2</span>),nn.ELU(),</span><br><span class="line">            nn.Conv1d(self.h,self.h,<span class="number">5</span>,<span class="number">2</span>),nn.ELU(),</span><br><span class="line">            nn.Conv1d(self.h,self.h,<span class="number">5</span>,<span class="number">1</span>),nn.ELU(),</span><br><span class="line">        )</span><br><span class="line">        self.lin=nn.Linear(self.h,<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y1=self.mol(x).squeeze(dim=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> self.lin(y1)</span><br><span class="line">mynn=Mol()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            out=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(out,tag):</span><br><span class="line">                x=x.argmax(dim=<span class="number">0</span>)</span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> x==y:</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率为&#123;:f&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>():</span><br><span class="line">    epoch=<span class="number">0</span></span><br><span class="line">    train_step=<span class="number">0</span></span><br><span class="line">    loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.Adam(mynn.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;批次:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            sen,tag=data</span><br><span class="line">            output=mynn(sen)</span><br><span class="line">            res_loss=loss_fn(output,tag)</span><br><span class="line">            res_loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            train_step+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss))</span><br><span class="line">        test_accuracy(test_load)</span><br><span class="line">        torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> exists(<span class="string">&quot;./model/final.pth&quot;</span>):</span><br><span class="line">    train_model()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br><span class="line">test_accuracy(val_load)</span><br></pre></td></tr></table></figure>
<p>输出:<code>准确率为0.707317</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/06/pytorchreview1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/06/pytorchreview1/" class="post-title-link" itemprop="url">Pytorch巩固1 one-hot 编码</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-06 10:22:34 / Modified: 11:15:33" itemprop="dateCreated datePublished" datetime="2024-03-06T10:22:34+08:00">2024-03-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>恶补pytorch系列,数据与项目内容来自：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ky4y1g7Nk/?p=2">链接</a>,代码是自己写的，和up可能不大一样</p>
<h1 id="one-hot">One-hot</h1>
<p>将句子分词后，生成一个向量 <span class="math inline">\(\vec{v}\)</span>,向量第 <span class="math inline">\(i\)</span>维为1当且仅当词<span class="math inline">\(i\)</span>出现过。 # 本次任务
数据集是csv文件，包括了单词转化为编码的形式，每个句子的标签（0，1二分类），train/val/test标注。
建立一个NN，本次重心不在backbone上，因此骨架只是一个单词数量映射到2的一个线性层。</p>
<h1 id="训练准备">训练准备</h1>
<p>由于每次训练的训练集数据都是批量拿取的，因此我们再复习下Dataset类和Dataloader的使用。</p>
<p>前置条件:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">word_num=<span class="number">8945</span></span><br></pre></td></tr></table></figure>
<h2 id="dataset-类">Dataset 类</h2>
<p>先调库: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br></pre></td></tr></table></figure> 读入数据: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src=pd.read_csv(<span class="string">&quot;data/数字化数据.csv&quot;</span>)</span><br></pre></td></tr></table></figure>
要继承Dataset类，需要写好构造函数<code>__init__()</code>,重写两个函数<code>__getitem__</code>与<code>__len__</code>。</p>
<p>构造函数可以记录一些基本的数据，记录好表示(比如train/val/test)
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,typ</span>):</span><br><span class="line">    self.typ=typ</span><br><span class="line">    self.data=src[src.part==typ]</span><br></pre></td></tr></table></figure> 这里存下了数据作用与对应的dataframe ### get_item
get_item会读入一个参数<code>idx</code>,函数要返回第<code>idx</code>个数据。</p>
<p>这里同时要对数据完成onehot编码，其中<code>-1</code>表示不认识这个词，忽略
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">    ts=torch.zeros(word_num,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    sentence=self.data.iloc[idx][<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">    seq=[<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> sentence.split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> seq:</span><br><span class="line">        <span class="keyword">if</span> x!=-<span class="number">1</span>:</span><br><span class="line">            ts[x]=<span class="number">1</span></span><br><span class="line">    tag=<span class="built_in">int</span>(self.data.iloc[idx][<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">    ts_tar=torch.zeros(<span class="number">2</span>,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    ts_tar[tag]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> ts,ts_tar</span><br></pre></td></tr></table></figure> ### len 返回数据集大小即可 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure></p>
<p>最后产生具体对象 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_set=mydata(<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure> ## Dataloader 调的库在 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure>
本质是用Dataloader类创建一个对象,几个参数如下: 1. dataset
就是Dataset类构建出来的 2. batch_size 每次取出的个数 3.
shuffle最好设为<code>True</code> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_load=DataLoader(dataset=train_set,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
同样的还要构造好<code>val_load</code>,<code>test_load</code> #
神经网络骨架 不是这次的重点，只整一个线性层: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mol</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mol=nn.Sequential(</span><br><span class="line">            nn.Linear(word_num,<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_out = self.mol(x)</span><br><span class="line">        <span class="keyword">return</span> y_out</span><br><span class="line">mynn=Mol()</span><br></pre></td></tr></table></figure>
模型单个数据最后会输出一个shape为(2)的tensor，分别表示0类和1类的概率。</p>
<h1 id="测试准确率">测试准确率</h1>
<p>注意在测试时模型参数不能动，因此要设置 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_accuracy</span>(<span class="params">data_load</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">        siz=<span class="number">0</span></span><br><span class="line">        ac=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_load:</span><br><span class="line">            sen,tag=data</span><br><span class="line">            out=mynn(sen)</span><br><span class="line">            <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(out,tag):</span><br><span class="line">                <span class="keyword">if</span> (x[<span class="number">0</span>]&gt;x[<span class="number">1</span>])==(y[<span class="number">0</span>]&gt;y[<span class="number">1</span>]):</span><br><span class="line">                    ac+=<span class="number">1</span></span><br><span class="line">                siz+=<span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;准确率为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(ac/siz))</span><br></pre></td></tr></table></figure>
# 训练过程 ## 工具
损失函数设定为交叉熵，优化器为随机梯度下降，学习速率为<code>0.01</code>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">    optim=torch.optim.SGD(mynn.parameters(),lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
训练分多个批次(epoch),每个批次都会把所有数据训练一遍，每次训练先算当前神经网络输出，再算损失函数，然后反向传播梯度下降。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练批次数：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_load:</span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        sen,tag=data</span><br><span class="line">        output=mynn(sen)</span><br><span class="line">        res_loss=loss_fn(output,tag)</span><br><span class="line">        res_loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        <span class="keyword">if</span> train_step%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;,loss=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_step,res_loss.item()))</span><br><span class="line">        train_step+=<span class="number">1</span></span><br><span class="line">    test_accuracy(test_load)</span><br><span class="line">    torch.save(mynn.state_dict(),<span class="string">&quot;./model/epoch&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br></pre></td></tr></table></figure> ## 模型保存/读取 这次我只保存了模型参数： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(mynn.state_dict(),<span class="string">&quot;./model/final.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
模型读取(要先创建好骨架)： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mynn.load_state_dict(torch.load(<span class="string">&quot;./model/final.pth&quot;</span>))</span><br></pre></td></tr></table></figure> ## 训练结果
<code>准确率为0.8693622448979592</code></p>
<h1 id="完整代码">完整代码</h1>
<p>后续放github上</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/03/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/03/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA%E4%BD%9C%E4%B8%9A/" class="post-title-link" itemprop="url">复杂度理论作业（第一次）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-03 10:02:54" itemprop="dateCreated datePublished" datetime="2024-03-03T10:02:54+08:00">2024-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-06 11:49:15" itemprop="dateModified" datetime="2024-03-06T11:49:15+08:00">2024-03-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>后续大多只简写了证明是NP-H,NP毕竟都比较显然就不写了。。。 # 1.Proof
sat is npc ## 先证 sat <span class="math inline">\(\in\)</span>
np-hard:</p>
<p>我们的目标是证明:sat难于任何np问题。考虑任何一个np问题<span class="math inline">\(L\)</span>，存在一个图灵机<span class="math inline">\(M\)</span>,<span class="math inline">\(x \in L
\Leftrightarrow \exist u \in \{0,1\}^{p(x)}
s.t.M(x,u)=1\)</span>,现在我们的目标是，将<span class="math inline">\(x\in L\)</span>这个条件多项式地转化为一个CNF。</p>
<p>对于上述TM，我们可以不依赖input纸带地找到它所有的configuration(详见zaq的ppt),对于一个<span class="math inline">\(x\)</span>,我们再设定<span class="math inline">\(p(x)\)</span>个布尔变量<span class="math inline">\(y_1,y_2....y_{p(x)}\)</span>,要判断<span class="math inline">\(M(x,\{y\})\)</span>是否会输出1，我们只需要判断以下条件：
1. 存在一个configuration sequence satisfying
每个configuration经过转移函数后都会到达下一个configuration（TM的定义）
2. 最后一个configuration 将会使TM halt and output <code>1</code>.
这可以在多项式复杂度内表示为两个CNF,因此我们成功将<span class="math inline">\(x\in L\)</span>转化为了一个CNF。</p>
<h2 id="再证-sat-in-npc">再证 sat <span class="math inline">\(\in\)</span> NPC</h2>
<p>只要证sat <span class="math inline">\(\in\)</span> NP,显然的。</p>
<h1 id="proof-sat-leq_p-3-sat">2. Proof <span class="math inline">\(SAT
\leq_{p} 3-SAT\)</span></h1>
<p>考虑一个<span class="math inline">\(k\)</span>元简单析取式<span class="math inline">\(A_1 \vee A_2 \vee A_3\vee...
A_k\)</span>加入一个新的变量<span class="math inline">\(z\)</span>,可以作如下化简</p>
<p><span class="math inline">\(A_1 \vee A_2 \vee A_3\vee... A_k = (A_1
\vee A_2 \vee...A_{k-2} \vee z)\wedge (A_{k-1} \vee A_k \vee
\bar{z})\)</span>,重复上述过程即可，可以发现重复次数显然是线性的，因此是合法的卡普规约.</p>
<h1 id="最大团是-npc">3. 最大团是 NPC</h1>
<p>我们已经证明了3-sat是NPC，因此我们只要证明 <span class="math inline">\(3-SAT \leq_{p}最大团问题\)</span>.</p>
<p>考虑任何一个CNF，我们建如下图：</p>
<p>对于m-clauses
CNF,我们建立一个m部图，对于每一个从句，我们将所有成真的赋值拉出来，看成一个顶点，可以发现最多会拉出<span class="math inline">\(2^3=7\)</span>个点，没有出现的变量用*代替。</p>
<p>然后，对于不矛盾的点，我们连一条边，最后只要判断最大团是否等于<span class="math inline">\(m\)</span>即可。</p>
<h1 id="整数规划是npc">4. 整数规划是NPC</h1>
<p>考虑证明：<span class="math inline">\(SAT \leq_{p}
整数规划\)</span></p>
<p>对于任意mclauses-CNF:<span class="math inline">\((A_1 \vee
A_2...)\wedge (B_1 \vee B_2 \vee...)...\)</span> 先限制所有字母为<span class="math inline">\(0 \leq x \leq 1\)</span>,一共<span class="math inline">\(m\)</span>个方程，再对每个析取式，写出<span class="math inline">\(\sum A_i \geq 1\)</span></p>
<p>显然，整数规划是NP的，因此得证。</p>
<h1 id="有向图哈密顿路是npc">5. 有向图哈密顿路是NPC</h1>
<p>考虑将问题规约到SAT。我们换一种视角来看待SAT问题，对于每个变量<span class="math inline">\(u\)</span>,如果<span class="math inline">\(u\)</span>取 <code>1</code>那么所有包含<span class="math inline">\(u\)</span>的从句都会被满足，如果<span class="math inline">\(u\)</span>取<code>0</code>那么所有包含<span class="math inline">\(\bar{u}\)</span>的从句将会被满足。</p>
<p>这次，我们按照变量来建图：</p>
<p>对于一个变量，我们单独对它建一层点：</p>
<figure>
<img src="lk.jpg" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>对于所有的从句<span class="math inline">\(c_1,c_2,c_3...c_m\)</span>,让他们相邻之间用双向边连接，规定从左往右是<code>True</code>,反之是<code>False</code>,如果取<code>True</code>时能让<span class="math inline">\(c_2\)</span>满足，那么就向点<span class="math inline">\(c_2\)</span>连边。</p>
<p>现在我们已经处理好了一个变量，要处理所有<span class="math inline">\(n\)</span>个变量，我们只需要建立起点st和终点ed，按如下方式把所有变量连起来:</p>
<figure>
<img src="tot.jpg" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>每一层的端点处向下一层两个端点都连边。很显然这个图如果存在哈密顿路径那么每一层走的方向就是SAT问题的答案。</p>
<h1 id="无向图哈密顿路径是npc">6.无向图哈密顿路径是NPC</h1>
<p>肯定是证明 <span class="math inline">\(有向图哈密顿路径 \leq_{p}
无向图哈密顿路径\)</span>.</p>
<p>那么给定一个有向图，我们要将它转化成一个无向图，使得哈密顿路存在性相同。对于一个节点，我们作如下转化：
<img src="conv.jpg" alt="图片">
将一个点拆成三个点，可以发现如果要经过中间那个点，一定是要走一个入边和一个出边.</p>
<h1 id="哈密顿回路是npc">7.哈密顿回路是NPC</h1>
<p>考虑将它规约到无向图哈密顿路径</p>
<p>对于原来的无向图，直接加一个点，连接其它所有点即可。</p>
<h1 id="tsp判定版本是否存在小于k的路径是npc">8.TSP判定版本(是否存在小于<span class="math inline">\(k\)</span>的路径)是NPC</h1>
<p>考虑归约到无向图哈密顿路径。</p>
<p>对于一个无向图，给它每条边赋权值<span class="math inline">\(\frac{k}{n-1}\)</span>即可</p>
<h1 id="section">9.</h1>
<p>证明下述语言是NPC:</p>
<p><span class="math inline">\(\{(\phi,1^n): 在ZF公理系统中，命题\phi
有长度至多为n 的证明\}\)</span></p>
<p>感觉就是规约到SAT？把一个CNF看成一个math statement?</p>
<p>(存疑) # 10.求证二次整数01规划(模2下)是NPC</p>
<p>考虑从3-SAT问题归约</p>
<p>对于任意3-CNF，某个变量会出现<span class="math inline">\(u\)</span>或<span class="math inline">\(\bar{u}\)</span>的形式。我们构造二次01规划问题，对于CNF中的每个变量,构造二次约束：<span class="math inline">\(u^2+\bar{u}^2=1\)</span>,容易验证这个等式就约束了<span class="math inline">\(u,\bar{u}\)</span>不同.</p>
<p>这样，我们生成了变量个数个二次约束，接下来，我们要解决每个从句的约束.</p>
<p>考虑到每个从句是一个简单析取式，考虑下列3种情况： 1.
从句只有一个变量<span class="math inline">\(A\)</span>,构造方程<span class="math inline">\(A^2=1\)</span>即可 2. 从句有两个变量<span class="math inline">\(A \vee B\)</span>,构造方程<span class="math inline">\(A^2+B^2+AB=1\)</span>即可 3. 从句有三个变量<span class="math inline">\(A \vee B \vee C\)</span>,构造新变量<span class="math inline">\(t_i\)</span>,增加方程</p>
<p><span class="math inline">\(\bar{A}\cdot
\bar{B}+{t_i}^2=0\)</span></p>
<p><span class="math inline">\(t_i \cdot \bar{C}=0\)</span></p>
<p>容易验证这些方程的解会是合法的3-SAT解。</p>
<h1 id="exact-one-3-sat">11.Exact one 3-sat</h1>
<p>从3-sat归约，对于原来的3-sat问题，先把表达式中出现在<span class="math inline">\(j\)</span>号从句的字母换成<span class="math inline">\(A_{i,j}\)</span>,然后再在末尾增加析取式<span class="math inline">\((\bar{A_i}\vee A_{i,j} \vee t_i)\)</span>
同样的，还可以证明NAE-3-SAT是NPC # 12. Subsetsum(问题的规模是<span class="math inline">\(\log值域\)</span>) 从Exact-one
3-sat归约，考虑一个exact-one 3-sat 问题，对于每个变量<span class="math inline">\(u\)</span>,如果它为真，那么将会满足某些从句，如果它为假，则会满足另一些从句，因此，对于每个变量，我们创建两个数，一个数在每个从句2倍二进制位设为1，这样可以阻止进位的发生，在从句个数+2*变量编号处也设为1（保证二择），要求的和就是<span class="math inline">\(\sum (2i)^2\)</span></p>
<h1 id="点覆盖独立集">13.点覆盖，独立集</h1>
<p>它们和最大团完全是一个东西，略</p>
<h1 id="maxcut-is-npc">14.Maxcut is NPC</h1>
<p>考虑从NAE-3-SAT归约。对于给定的CNF，每个从句的每个字母都看成一个点，从句之间互相连边，形成许多二元环和三元环，考虑赋值不同的节点之间cut,这样三元环最多贡献是2，二元环是1。</p>
<p>但注意到同一变量在不同的从句之间的约束，因此，我们在一对相反的变量之间添加很多(比m多一个级别？比如<span class="math inline">\(m^2\)</span>)边，相当于惩罚，如果这俩点一样就少cut了这么多条边。最后把边都加上，看看是不是<span class="math inline">\(2 \cdot 三元环+重边\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/02/28/lattice-fix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meiqwq">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Meiqwq's blog~">
      <meta itemprop="description" content="A blog correlated with CS">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Meiqwq's blog~">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/28/lattice-fix/" class="post-title-link" itemprop="url">Tarski upper bound 导读</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-02-28 20:52:50" itemprop="dateCreated datePublished" datetime="2024-02-28T20:52:50+08:00">2024-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-06 23:44:45" itemprop="dateModified" datetime="2024-03-06T23:44:45+08:00">2024-03-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>作者应该是俩中国人</p>
<h1 id="tarski定理">Tarski定理</h1>
<p>对于完全格 <span class="math inline">\(&lt;L,\preceq&gt;\)</span>,以及<span class="math inline">\(L \to L\)</span>的单调增函数<span class="math inline">\(f\)</span>，<span class="math inline">\(f\)</span>一定存在不动点</p>
<p>有点像格上的介值定理 # 文章贡献 对于n阶k维格点格(grid
lattice),以及定义在其上的单调不降函数<span class="math inline">\(f\)</span>,构造出了一个<span class="math inline">\(O(\log^{\lceil \frac{k+1}{2}
\rceil}n)\)</span>算法找到一个不动点。</p>
<p>后文假设我们的目标是解决<span class="math inline">\(Tarski(n,k+1)\)</span> # Step1 Reduce to <span class="math inline">\(Tarski*(n,k)\)</span> <img src="exp.jpg" alt="图片">
我们可以单独考虑某一个维度，先固定这个维度的值（也就是说取在这个格中取出一个切片）我们尝试在这个切面上找到一个prefix或者suffix。(前驱或者后继是一定存在的，因为只考虑这个切面(<span class="math inline">\(k\)</span>维)上，一定存在不动点，这个点肯定是一个前驱或后继),很显然哉suffix到<span class="math inline">\([n]^{k+1}\)</span>之间（或<span class="math inline">\([1]^{k+1}\)</span>到prefix之间）一定有不动点，于是第<span class="math inline">\(k+1\)</span>维减半。</p>
<p>prefix: 指一个点<span class="math inline">\(x\)</span>满足<span class="math inline">\(f(x) \preceq x\)</span></p>
<p>suffix:指一个点<span class="math inline">\(x\)</span>满足<span class="math inline">\(x \preceq f(x)\)</span> ## <span class="math inline">\(Tarski*(n,k)\)</span> <img src="tarskis.png" alt="图片"></p>
<h2 id="reduction">Reduction</h2>
<figure>
<img src="red.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>问题转变为求解<span class="math inline">\(Tarski*(n,k)\)</span>,假设求解<span class="math inline">\(Tarski*(n,k)\)</span>的复杂度是<span class="math inline">\(q(n,k)\)</span>，那么，求解<span class="math inline">\(Tarski(n,k)\)</span>的复杂度是<span class="math inline">\(O(2^k+k\log n\cdot q(n,k))\)</span></p>
<h1 id="refined-tarskink"><span class="math inline">\(Refined
Tarski*(n,k)\)</span></h1>
<figure>
<img src="ref.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h2 id="求解">求解</h2>
<figure>
<img src="note.jpg" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h1 id="求解-tarskinab">求解 <span class="math inline">\(Tarski*(n,a+b)\)</span></h1>
<p>现在的目标是，假设我们能求解<span class="math inline">\(Tarski*(n,a),Tarski*(n,b)\)</span>如何求解<span class="math inline">\(Tarski*(n,a+b)\)</span></p>
<p>一个很自然的想法是，对于<span class="math inline">\([a+1,a+b]\)</span>维，我们直接枚举它们的值（假设枚举了<span class="math inline">\(q_i\)</span>）然后我们执行如下算法:</p>
<figure>
<img src="part.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>此时我们会发现，在前<span class="math inline">\(a\)</span>维的切面上，<span class="math inline">\(p^{(l,i)},p^{(r,i)}\)</span>之间的点，这些点的<span class="math inline">\(g(x)\)</span>在<span class="math inline">\(a+1\)</span>维之后都相等(由于Refined
Tarski*的作用),前<span class="math inline">\(a\)</span>维肯定非负或非正，因此，如果我们能保证<span class="math inline">\([a+1,a+b+1]\)</span>维也非负/非正，那么就做完了。</p>
<p>如何保证呢，我们发现实际上这可以转化成一个求解<span class="math inline">\(Tarski(n,b)\)</span>的过程,如果我们可以保证对<span class="math inline">\(q_i\)</span>的回复满足
<code>Definition2</code>，那么最终就能找到一组非正或非负的回复。</p>
<figure>
<img src="ker.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>在这里，每次询问<span class="math inline">\(q_i\)</span>时，我们都会找到之前的询问记录，保证下界要比以前的大，上界要比以前的小，这样的回复一定是可以满足<code>Definition2</code>的（因为<span class="math inline">\((q_i,0)+g(p^{(l,i)},q_i)\)</span>关于<span class="math inline">\(q_i\)</span>单调）。因此，假设<span class="math inline">\(Tarski*(n,a)\)</span>复杂度是<span class="math inline">\(q(n,a)\)</span>,<span class="math inline">\(Tarski*(n,b)\)</span>复杂度是<span class="math inline">\(q(n,b)\)</span>，那么我们在<span class="math inline">\(O((b+1)q(n,a)q(n,b))\)</span>内完成了<span class="math inline">\(Tarski*(n,a+b)\)</span></p>
<h1 id="最后">最后</h1>
<p>由于<span class="math inline">\(Tarski*(n,2)\)</span>可以在<span class="math inline">\(O(\log n)\)</span>内完成，因此<span class="math inline">\(Tarski*(n,k)\)</span>可以在<span class="math inline">\(O(\log^{k/2}n)\)</span>完成,进而证明了Tarski(n,k)的复杂度</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Meiqwq</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
